<!DOCTYPE html>
<html lang="en-us">
    <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="format-detection" content="telephone=no" />

  <title>
    Lựa chọn features cho XGBoost model | ML in Practical
  </title>

  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/manifest.json" />
  <meta name="theme-color" content="#ffffff" />

  
  <link
    rel="stylesheet"
    href="https://unpkg.com/modern-normalize@0.6.0/modern-normalize.css"
  />

  
  
  
  
  <link rel="stylesheet" href="https://tiensu.github.io/style.min.f7761d111b74dd5c07f0111decee92938c12abc42e0fd319e1a07483e248b54e.css" integrity="sha256-93YdERt03VwH8BEd7O6Sk4wSq8QuD9MZ4aB0g&#43;JItU4=" />

  
  
    
  
</head>

    <body>
        <header id="header">
  <div class="header_container">
    <h1 class="sitetitle">
      <a href="https://tiensu.github.io/" title="ML in Practical">ML in Practical</a>
    </h1>
    <nav class="navbar">
      <ul>
        <li><a href="https://tiensu.github.io/">Home</a></li>
        
          <li>
            <a href="/about/">
              
              <span>About</span>
            </a>
          </li>
        
          <li>
            <a href="/tags/">
              
              <span>Tags</span>
            </a>
          </li>
        
          <li>
            <a href="/archives/">
              
              <span>Archives</span>
            </a>
          </li>
        
        <li class="hide-sm"><a href="https://tiensu.github.io/index.xml" type="application/rss+xml">RSS</a></li>
      </ul>
    </nav>
  </div>
</header>

        
<section id="main">
  <article class="post content">
    <h2 class="title">Lựa chọn features cho XGBoost model</h2>
    <div class="post_content">
      <p><code>Feature selection</code> hay <em>lựa chọn features</em> là một bước tương đối quan trọng trước khi train XGBoost model. Lựa chọn đúng các <code>features</code> sẽ giúp model khái quát hóa vấn đề tốt hơn (<code>low variance</code>) -&gt; đạt độ chính xác cao hơn.</p>
<p>Trong bài viết này, hãy cùng xem xét về cách dùng thư viện <code>XGBoost</code> để tính <code>importance scores</code> và thể hiện nó trên đồ thị, sau đó lựa chọn các <code>features</code> để train XGBoost model dựa trên <code>importance scores</code> đó.</p>
<p><strong>1. Tính và hiển thị <code>importance score</code> trên đồ thị</strong></p>
<p><em><strong>1.1 Cách 1</strong></em></p>
<p>Model XGBoost đã train sẽ tự động tính toán mức độ quan trọng của các <code>features</code>. Các giá trị này được lưu trong biến <code>feature_importances_</code> của model đã train. Kiểm tra bằng cách:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)</span>
</code></pre></div><p>Thể hiện các <code>features importance</code> lên đồ thị:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># plot</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)),</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>Code dưới đây minh họa đầy đủ việc train XGBoost model trên tập dữ liệu <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabet">Pima Indians onset of diabetes</a> và hiển thị các <code>features importances</code> lên đồ thị:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># plot feature importance manually</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">loadtxt</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># load data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;pima-indians-diabetes.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
<span class="c1"># split data into X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>
<span class="c1"># fit model on training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># feature importance</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)</span>
<span class="c1"># plot</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)),</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>Chạy code trên, <code>importance score</code> được in ra:</p>
<pre><code>[0.10621197 0.2424023  0.08803366 0.07818192 0.10381887 0.1486732
 0.10059207 0.13208601]
</code></pre><p>và đồ thị:
<figure>
    <img src="/plot_feature_importance_1.png" width="1000"/> 
</figure>
</p>
<p><em><strong>1.2 Cách 2</strong></em></p>
<p>Nhược điểm của cách này là các <code>importance scores</code> được sắp xếp theo thứ tự của các <code>features</code> trong tập dataset. Điều này làm cho chúng ta khó quan sát trong trường hợp số lượng <code>features</code> lớn. Liệu có thể sắp thứ tự các <code>importance scores</code> này theo giá trị của chúng được hay không? Câu trả lời là có thể. Thư viện <code>XGBoost</code> có một hàm gọi là <code>plot_importance()</code> giúp chúng ta thực hiện việc này.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># plot feature importance</span>
<span class="n">plot_importance</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>Code dưới đây minh họa đầy đủ việc train XGBoost model trên tập dữ liệu <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabet">Pima Indians onset of diabetes</a> và hiển thị các <code>features importances</code> lên đồ thị:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># plot feature importance using built-in function</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">loadtxt</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">plot_importance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># load data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;pima-indians-diabetes.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
<span class="c1"># split data into X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>
<span class="c1"># fit model on training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># plot feature importance</span>
<span class="n">plot_importance</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>Chạy code ví dụ bên trên thu được kết quả:
<figure>
    <img src="/plot_feature_importance_2.png" width="1200" height="650"/> 
</figure>
</p>
<p>Quan sát đồ thị ta thấy, các <code>features</code> được tự động đặt tên từ <code>f0</code> đến <code>f7</code> theo thứ tự của chúng trong mảng dữ liệu input X. Từ đồ thị có thể kết lụân rằng:</p>
<ul>
<li>f6 có <code>importance score</code> cao nhất - 333</li>
<li>f4 có <code>importance score</code> thấp nhất - 124</li>
</ul>
<p>Nếu có bảng mô tả dữ liệu, ta có thể ánh xạ f4, f6 thành tên các <code>features</code> tương ứng.</p>
<p><strong>2. Lựa chọn <code>features</code> (<em>feature selection</em>) theo <code>importance scores</code></strong></p>
<p>Thư viện <code>scikit-learn</code> cung cấp lớp <code>SelectFromModel</code> cho phép lựa chọn các <code>features</code> để train model. Lớp này yêu cầu 2 tham số bắt buộc:</p>
<ul>
<li><em>model</em>: model đã được train trên toàn bộ dataset.</li>
<li><em>threshold</em>: ngưỡng để lựa chọn <code>features</code>. Chỉ những <code>features</code> có <code>importance score</code> không nhỏ hơn ngưỡng mới được lựa chọn.
Sau khi gọi hàm <code>transform()</code> thì lớp <code>SelectFromModel</code> sẽ chuyển đổi tập dữ liệu ban đầu thành tập dữ liệu nhỏ hơn chỉ bao gồm các <code>features</code> được chọn.</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># select features using threshold</span>
<span class="n">selection</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">thresh</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">select_X_train</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</code></pre></div><p>Sau khi có tập dữ liệu mới, ta tiến hành train và đánh giá model mới tạo ra như bình thường.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># train model</span>
<span class="n">selection_model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">selection_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">select_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># eval model</span>
<span class="n">select_X_test</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">selection_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">select_X_test</span><span class="p">)</span>
</code></pre></div><p>Trong các bài toán thực tế, ta thường không biết chính xác giá trị nào của <code>threshold</code> là phù hợp. Vì vậy mà ta sẽ <code>tuning</code> giá trị này bằng phương pháp <code>grid-seach</code> (<em>mình sẽ có 1 bài viết riêng giải thích chi tiết về các phương pháp tuning hyper-parameters. Ở đây, bạn chỉ cần hiểu một cách đơn giản là kiểm tra với nhiều giá trị của <code>threshold</code> để chọn ra giá trị tốt nhất</em>). Chúng ta sẽ bắt đầu kiểm tra với tất cả <code>features</code>, kết thúc với <code>feature</code> quan trọng nhất.</p>
<p>Code hoàn chỉnh như bên dưới:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># use feature importance for feature selection</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">loadtxt</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">sort</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>
<span class="c1"># load data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;pima-indians-diabetes.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
<span class="c1"># split data into X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>
<span class="c1"># split data into train and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="c1"># fit model on all training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># make predictions for test data and evaluate</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Accuracy: </span><span class="si">%.2f%%</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
<span class="c1"># Fit model using each importance as a threshold</span>
<span class="n">thresholds</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)</span>
<span class="k">for</span> <span class="n">thresh</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
<span class="c1"># select features using threshold</span>
<span class="n">selection</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">thresh</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">select_X_train</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="c1"># train model</span>
<span class="n">selection_model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">selection_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">select_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># eval model</span>
<span class="n">select_X_test</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">selection_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">select_X_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Thresh=</span><span class="si">%.3f</span><span class="s2">, n=</span><span class="si">%d</span><span class="s2">, Accuracy: </span><span class="si">%.2f%%</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">thresh</span><span class="p">,</span> <span class="n">select_X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">accuracy</span><span class="o">*</span><span class="mf">100.0</span><span class="p">))</span>
</code></pre></div><p>Chạy code trên thu được kết quả như sau:</p>
<pre><code>Accuracy: 74.02%
Thresh=0.088, n=8, Accuracy: 74.02%
Thresh=0.089, n=7, Accuracy: 71.65%
Thresh=0.098, n=6, Accuracy: 71.26%
Thresh=0.098, n=5, Accuracy: 74.41%
Thresh=0.100, n=4, Accuracy: 74.80%
Thresh=0.136, n=3, Accuracy: 71.26%
Thresh=0.152, n=2, Accuracy: 71.26%
Thresh=0.240, n=1, Accuracy: 67.32%
</code></pre><p>Có thể thấy rằng độ chính xác của model cao nhất trên tập dữ liệu gồm 4 <code>features</code> quan trọng nhất và thấp nhất trên tập dữ liệu chỉ gồm một <code>feature</code>.</p>
<p><code>Tuning</code> theo kiểu <code>grid-seach</code> như này đặc biệt hiệu quả trong trường hợp bộ dữ liệu lớn.</p>
<p><strong>3. Kết luận</strong></p>
<p>Trong bài viết này, chúng ta đã tìm hiểu cách thể hiện <code>importance score</code> của các <code>features</code> trên đồ thị và sử dụng <code>importance score</code> để lựa chọn các <code>features</code> sao cho model đạt được độ chính xác cao nhất.</p>
<p>Bài viết tiếp theo ta sẽ tìm hiểu cách giám sát (<em>monitor</em>) hiệu năng của model trong quá trình train và cấu hình <code>early stop</code> (<em>dừng train khi model đáp ứng một tiêu chí nào đó</em>). Hai kỹ thuật này rất cần thiết để train một XGBoost model tốt. Hãy cùng đón đọc! :)</p>
<p><em>Toàn bộ source code của bài này các bạn có thể tham khảo trên github cá nhân của mình tại <a href="https://github.com/tiensu/XGBoost-algorithm/tree/master/feature_selection">github.</a></em></p>
<p>Bài viết có tham khảo tại <a href="https://machinelearningmastery.com/XGBoost-with-python/">tham khảo</a>.</p>

    </div>
    <div class="info post_meta">
      <time datetime=2020-09-27T00:00:00Z class="date">Sunday, September 27, 2020</time>
      
        <ul class="tags">
        
          <li> <a href="https://tiensu.github.io/tags/ai">AI</a> </li>
        
          <li> <a href="https://tiensu.github.io/tags/ml">ML</a> </li>
        
          <li> <a href="https://tiensu.github.io/tags/XGBoost">XGBoost</a> </li>
        
        </ul>
      
      
    </div>
    <div class="clearfix"></div>
  </article>
  
    <div class="other_posts">
      
      <a href="https://tiensu.github.io/posts/save-load-XGBoost-model/" class="prev">Lưu và sử dụng XGBoost model</a>
      
      
      <a href="https://tiensu.github.io/posts/monitor_trainig_early_stopping/" class="next">Giám sát quá trình train và cấu hình Early_Stopping cho XGBoost model</a>
      
    </div>
    <aside id="comments">
</aside>

  
</section>

        <a id="back_to_top" title="Go To Top" href="#">
  <span>
    <svg viewBox="0 0 24 24">
      <path fill="none" d="M0 0h24v24H0z"></path>
      <path d="M12 2L4.5 20.29l.71.71L12 18l6.79 3 .71-.71z"></path>
    </svg>
  </span>
</a>

        <footer id="footer">
  <p>
    <span>&copy; 2020 <a href="https://tiensu.github.io/" title="ML in Practical">ML in Practical</a> </span>
    <span>Built with <a rel="nofollow" target="_blank" href="https://gohugo.io">Hugo</a></span>
    <span>Theme by <a rel="nofollow" target="_blank" href="https://github.com/wayjam/hugo-theme-mixedpaper">WayJam</a></span>
  </p>

  <script src="https://tiensu.github.io/js/main.min.8b182175f5874aeed0acc0979345c98d4bde22208ec4f36cc1d6e3102acb4b10.js" integrity="sha256-ixghdfWHSu7QrMCXk0XJjUveIiCOxPNswdbjECrLSxA=" crossorigin="anonymous" async></script>
</footer>

    </body>
</html>
