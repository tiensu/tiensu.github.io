<!DOCTYPE html>
<html lang="en-us">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="format-detection" content="telephone=no" />

    <title>
        XGBoost - Bài 1: Toàn cảnh về Ensemble Learning - Phần 1 | ML in Practical
    </title>


    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/manifest.json" />
    <meta name="theme-color" content="#ffffff" />


    <link rel="stylesheet" href="https://unpkg.com/modern-normalize@0.6.0/modern-normalize.css" />





    <link rel="stylesheet" href="https://tiensu.github.io/style.min.388cbd0ce358245ec0dfcee3b8889b3cc50e2bb8a5b2bcd40f8bd092ebefb81a.css" integrity="sha256-OIy9DONYJF7A387juIibPMUOK7ilsrzUD4vQkuvvuBo=" />




    <script type="application/javascript">
        var doNotTrack = false;
        if (!doNotTrack) {
            (function(i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function() {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                    m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
            ga('create', 'UA-180180568-1', 'auto');
            ga('set', 'anonymizeIp', true);
            ga('send', 'pageview');
        }
    </script>


</head>

<body>
    <header id="header">

        <script type="application/javascript">
            var doNotTrack = false;
            if (!doNotTrack) {
                (function(i, s, o, g, r, a, m) {
                    i['GoogleAnalyticsObject'] = r;
                    i[r] = i[r] || function() {
                        (i[r].q = i[r].q || []).push(arguments)
                    }, i[r].l = 1 * new Date();
                    a = s.createElement(o),
                        m = s.getElementsByTagName(o)[0];
                    a.async = 1;
                    a.src = g;
                    m.parentNode.insertBefore(a, m)
                })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
                ga('create', 'UA-180180568-1', 'auto');
                ga('set', 'anonymizeIp', true);
                ga('send', 'pageview');
            }
        </script>

        <div class="header_container">
            <h1 class="sitetitle">
                <a href="https://tiensu.github.io/" title="ML in Practical">ML in Practical</a>
            </h1>
            <nav class="navbar">
                <ul>
                    <li><a href="https://tiensu.github.io/">Home</a></li>

                    <li>
                        <a href="/about/">

                            <span>About</span>
                        </a>
                    </li>

                    <li>
                        <a href="/tags/">

                            <span>Tags</span>
                        </a>
                    </li>

                    <li>
                        <a href="/archives/">

                            <span>Archives</span>
                        </a>
                    </li>

                    <li class="hide-sm"><a href="https://tiensu.github.io/index.xml" type="application/rss+xml">RSS</a></li>
                </ul>
            </nav>
        </div>
        <script>
            MathJax = {
                tex: {
                    inlineMath: [
                        ['$', '$'],
                        ['\\(', '\\)']
                    ],
                    displayMath: [
                        ['$$', '$$'],
                        ['\\[', '\\]']
                    ],
                    processEscapes: true,
                    processEnvironments: true
                },
                options: {
                    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                }
            };

            window.addEventListener('load', (event) => {
                document.querySelectorAll("mjx-container").forEach(function(x) {
                    x.parentElement.classList += 'has-jax'
                })
            });
        </script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


    </header>


    <section id="main">
        <article class="post content">
            <h2 class="title">XGBoost - Bài 1: Toàn cảnh về Ensemble Learning - Phần 1</h2>
            <div class="post_content">
                <p><strong>1. Giới thiệu về <code>Ensemble Learning</code></strong></p>
                <p>Giả sử chúng ta có một bài toán phân loại sản phẩm sử dụng ML. Team của bạn chia thành 3 nhóm, mỗi nhóm sử dụng một thuật toán khác nhau và đánh giá độ chính xác trên tập <code>validation set</code>:</p>
                <ul>
                    <li>Nhóm 1: Sử dụng thuật toán <code>Linear Regression</code>.</li>
                    <li>Nhóm 2: Sử dụng thuật toán <code>k-Nearest Neighbour</code>.</li>
                    <li>Nhóm 3: Sử dụng thuật toán <code>Decision Tree</code>. Độ chính xác của mỗi nhóm lần lượt là 70%, 67% và 76%. Điều này hoàn toàn dễ hiểu bởi vì 3 models làm việc theo những các khác nhau. Ví dụ, <code>Linear Regression</code> cố gắng
                        tìm ra mối quan hệ tuyến tính giữa các điểm dữ liệu, trong khi <code>Decision Tree</code> thì lại dựa vào mỗi quan hệ phi tuyến để liên kết dữ liệu.</li>
                </ul>
                <p>Có cách nào kết hợp kết quả cả 3 models để tạo ra kết quả cuối cùng hay không?</p>


                <div style="text-align:center">
                    <img src="/Ensemble_Learning.webp">
                </div>


                <p>Câu hỏi này là tiền đề cho một phương pháp, một họ các thuật toán hoạt động rất hiệu quả trong các bài toán ML. Đó là <code>Ensemble Learning</code> hay <code>Ensemble Models</code>.</p>
                <p>Hình dưới đây thể hiện bức tranh tổng quát về <code>Ensemble Learning</code>.</p>


                <div style="text-align:center">
                    <img src="/Ensemble_Learning_2.png">
                </div>


                <p><strong>2. Basic Ensemble Techniques</strong></p>
                <p>Ở mức độ cơ bản, có 3 kỹ thuật là:</p>
                <ul>
                    <li>Max Voting</li>
                    <li>Averaging</li>
                    <li>Weighted Averaging Mặc dù đơn giản nhưng những kỹ thuật này lại tỏ ra hiệu quả trong một số trường hợp nhất định. Hãy cùng tìm hiểu kỹ hơn về chúng.</li>
                </ul>
                <p><em><strong>2.1 Max Voting</strong></em></p>
                <p>Kỹ thuật này hay được sử dụng cho bài toán phân lớp, ở đó, nhiều models được sử dụng để dự đoán cho mỗi mẫu dữ liệu. Kết quả dự đoán của mỗi model được xem như là một <code>vote</code>. Cái nào có số <code>vote</code> cao nhất thì sẽ là
                    kết quả dự đoán cuối cùng. Nói cách khác, đây là kiểu bầu chọn theo số đông, được áp dụng rất nhiều trong cuộc sống, chính trị, &hellip;</p>
                <p>Lấy ví dụ, đợt vừa rồi, công ty của bạn tổ chức khám sức khỏe cho nhân viên tại bệnh viện X. Sau khi khám xong, phòng tổ chức nhân sự (TCNS) lấy ý kiến mọi người về chất lượng khám bệnh để xem năm sau có tiếp tục khám ở bênh viên X đó
                    nữa không. Bảng dưới là ý kiến của 5 người được chọn ngẫu nhiên trong số toàn bộ nhân viên.</p>
                <table>
                    <thead>
                        <tr>
                            <th align="center">Người 1</th>
                            <th align="center">Người 2</th>
                            <th align="center">Người 3</th>
                            <th align="center">Người 4</th>
                            <th align="center">Người 5</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td align="center">Có</td>
                            <td align="center">Không</td>
                            <td align="center">Không</td>
                            <td align="center">Có</td>
                            <td align="center">Có</td>
                        </tr>
                    </tbody>
                </table>
                <p>Có 3 ý kiến muốn tiêp tục khám ở bệnh viện X vào năm sau, và 2 ý kiến muốn đổi bênh viện khác. Căn cứ theo <code>max voting</code> thì phòng TCNS sẽ tiếp tục chọn bệnh viên Xlà nơi khám bệnh cho nhân viên cho năm tiếp theo.</p>
                <p>Code minh họa:</p>
                <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model_2</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">model_3</span><span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model_3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">pred_1</span><span class="o">=</span><span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">pred_2</span><span class="o">=</span><span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">pred_3</span><span class="o">=</span><span class="n">model_3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">final_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">)):</span>
    <span class="n">final_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_pred</span><span class="p">,</span> <span class="n">mode</span><span class="p">([</span><span class="n">pred_1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">pred_2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">pred_3</span><span class="p">[</span><span class="n">i</span><span class="p">]]))</span>
</code></pre></div>
                <p>Thư viện <code>scikit-learn</code> có module <code>VotingClassifier</code> giúp chúng ta đơn giản hóa việc này:</p>
                <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_2</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">model_1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">model_2</span><span class="p">)],</span> <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
                <p><em><strong>2.2 Averaging</strong></em></p>
                <p>Tương tự như kỹ thuật <code>Voting</code>, <code>Averaging</code> cũng sử dụng kết quả dự đoán của nhiều models. Tuy nhiên, ở bước quyết định kết quả cuối cùng, giá trị trung bình của tất cả kêt quả của các models được lựa chọn.</p>


                <div style="text-align:center">
                    <img src="/average.PNG">
                </div>


                <p>Tiếp tục với ví dụ ở trên, một đề nghị khác của phòng TCNS là yêu cầu nhân viên chấm điểm chất lượng khám bệnh của bênh viện X, theo thang điểm từ 1 đến 5.</p>
                <p>Bảng kết quả trả lời của 5 người ngẫu nhiên:</p>
                <table>
                    <thead>
                        <tr>
                            <th align="center">Người 1</th>
                            <th align="center">Người 2</th>
                            <th align="center">Người 3</th>
                            <th align="center">Người 4</th>
                            <th align="center">Người 5</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td align="center">2</td>
                            <td align="center">4</td>
                            <td align="center">3</td>
                            <td align="center">5</td>
                            <td align="center">4</td>
                        </tr>
                    </tbody>
                </table>
                <p>Điểm đánh giá cuối cùng sẽ là: <strong>(2+4+3+5+4)/5 = 3.6</strong></p>
                <p>Code ví dụ:</p>
                <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model_2</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">model_3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model_3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">pred_1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">pred_2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">pred_3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">final_pred</span> <span class="o">=</span><span class="p">(</span><span class="n">pred1</span><span class="o">+</span><span class="n">pred2</span><span class="o">+</span><span class="n">pred3</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span>
</code></pre></div>
                <p><em><strong>2.3 Weighted Average</strong></em></p>
                <p>Đây là kỹ thuật mở rộng của <code>averaging</code>. Mỗi model được gắn kèm với một trọng số tỷ lệ với mức độ quan trọng của model đó. Kết quả cuối cùng là trung bình có trọng số của tất cả kết quả của các models.</p>


                <div style="text-align:center">
                    <img src="/weighted.PNG">
                </div>


                <p>Vẫn với ví dụ ở mục 2.2, nhưng trong số 5 người được hỏi thì người thứ nhất có vợ là bác sĩ, người thứ 2 có mẹ là y tá, người thứ 3 có người yêu là sinh viên trường y. Vì vậy, ý kiến của 3 người này rõ ràng có giá trị hơn so với 2 người
                    còn lại. Ta đánh trọng số cho mỗi người như bảng dưới (<em>hàng thứ 2 là trọng số, hàng thứ 3 là điểm đánh giá</em>):</p>
                <table>
                    <thead>
                        <tr>
                            <th align="center">Người 1</th>
                            <th align="center">Người 2</th>
                            <th align="center">Người 3</th>
                            <th align="center">Người 4</th>
                            <th align="center">Người 5</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td align="center">1</td>
                            <td align="center">0.8</td>
                            <td align="center">0.5</td>
                            <td align="center">0.3</td>
                            <td align="center">0.3</td>
                        </tr>
                        <tr>
                            <td align="center">2</td>
                            <td align="center">4</td>
                            <td align="center">3</td>
                            <td align="center">5</td>
                            <td align="center">4</td>
                        </tr>
                    </tbody>
                </table>
                <p>Điểm đánh giá cuối cùng sẽ là: <strong>(2<em>1 + 4</em>0.8 + 3<em>0.5 + 5</em>0.3 + 4*0.3)/5 = 1.88</strong></p>
                <p>Code minh họa:</p>
                <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model_2</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">model_3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model_3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">pred_1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">pred_2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">pred_3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">final_pred</span><span class="o">=</span><span class="p">(</span><span class="n">pred_1</span><span class="o">*</span><span class="mf">0.3</span> <span class="o">+</span> <span class="n">pred_2</span><span class="o">*</span><span class="mf">0.3</span> <span class="o">+</span> <span class="n">pred_3</span><span class="o">*</span><span class="mf">0.4</span><span class="p">)</span>
</code></pre></div>
                <p><strong>3. Advanced Ensemble techniques</strong></p>
                <p>Đã có <code>basic</code> thì chắc chắn phải có <code>advanced</code>, phải không mọi người. :D</p>
                <p>Có 4 kỹ thuật của <code>Ensemble Learning</code> được xếp vào nhóm <code>advanced</code>:</p>
                <ul>
                    <li>Stacking</li>
                    <li>Blending</li>
                    <li>Bagging</li>
                    <li>Boosting</li>
                </ul>
                <p>Chúng ta tiếp tục đi qua lần lượt từng kỹ thuật này:</p>
                <p><em><strong>3.1 Stacking</strong></em></p>
                <p>Hãy xem các bước thực hiện của kỹ thuật này:</p>
                <ul>
                    <li>Bước 1: Train model A (<em>base model</em>) theo kiểu <code>cross-validation</code> với k=10.</li>
                    <li>Bước 2: Tiếp tuc train model A trên toàn bộ <code>train set</code>.</li>
                    <li>Bước 3: Sử dụng model A để dự đoán trên <code>test set</code>.</li>
                    <li>Bước 4: Lặp lại bước 1,2,3 cho các <code>base model</code> khác.</li>
                    <li>Bước 5:
                        <ul>
                            <li>Kết quả dự đoán trên <code>train set</code> của các <code>base models</code> được sử dụng như là <code>input features</code> (<code>ensemble train set</code>) để train <code>stacking model</code>.</li>
                            <li>Kết quả dự đoán trên <code>test set</code> của các <code>base models</code> được sử dụng như là <code>test set</code> (<code>ensemble test set</code>) của <code>stacking model</code>.</li>
                        </ul>
                    </li>
                    <li>Bước 6: Train và đánh giá <code>stacking model</code> sử dụng <code>ensemble train set</code> và <code>ensemble test set</code>.</li>
                </ul>
                <p>Code minh họa ý tưởng:</p>
                <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># We first define a function to make predictions on n-folds of train and test dataset. This function returns the predictions for train and test for each model.</span>
<span class="k">def</span> <span class="nf">Stacking</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">train</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="n">n_fold</span><span class="p">):</span>
    <span class="n">folds</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_fold</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">train_indices</span><span class="p">,</span><span class="n">val_indices</span> <span class="ow">in</span> <span class="n">folds</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
        <span class="n">x_train</span><span class="p">,</span><span class="n">x_val</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span><span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>
        <span class="n">y_train</span><span class="p">,</span><span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">train_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_pred</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
        <span class="n">test_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_pred</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">test_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">train_pred</span>

<span class="c1"># Now we’ll create two base models – decision tree and knn.</span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_pred_1</span> <span class="p">,</span><span class="n">train_pred_1</span> <span class="o">=</span> <span class="n">Stacking</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_1</span><span class="p">,</span> <span class="n">n_fold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">train_pred_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_pred_1</span><span class="p">)</span>
<span class="n">test_pred_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_pred_1</span><span class="p">)</span>

<span class="n">model_2</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">test_pred_2</span><span class="p">,</span> <span class="n">train_pred_2</span> <span class="o">=</span> <span class="n">Stacking</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_2</span><span class="p">,</span> <span class="n">n_fold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span><span class="n">test</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">train_pred_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_pred_2</span><span class="p">)</span>
<span class="n">test_pred_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_pred_2</span><span class="p">)</span>

<span class="c1"># Create a final model, logistic regression, on the predictions of the decision tree and knn models.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train_pred_1</span><span class="p">,</span> <span class="n">train_pred_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">test_pred_1</span><span class="p">,</span> <span class="n">test_pred_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">df_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
                <p>Đoạn code trên chỉ minh họa <code>stack model</code> với 2 levels. <code>Decision Tree</code> và <code>kNN</code> là level 0, còn <code>Logistic Regression</code> là level 1. Bạn hoàn toàn có thể thử nghiệm với nhiều levels hơn.</p>
                <p><em><strong>3.2 Blending</strong></em></p>
                <p>Các bước thực hiện phương pháp này như sau:</p>
                <ul>
                    <li>Buớc 1: Chia dataset thành <code>train set</code>, <code>validation set</code> và <code>test set</code>.</li>
                    <li>Bước 2: <code>Base model</code> được train trên <code>train set</code>.</li>
                    <li>Bước 3: Sử dụng <code>base model</code> để dự đoán trên <code>validation set</code> và <code>test set</code>.</li>
                    <li>Bước 4: Lặp lại bước 2,3 cho các <code>base models</code> khác.</li>
                    <li>Bước 5:
                        <ul>
                            <li><code>Validation set</code> và các kết quả dự đoán trên <code>validation set</code> của các <code>base models</code> được sử dụng như là <code>input features</code> (<code>ensemble train set</code>) của <code>blending model</code>.</li>
                            <li><code>Test set</code> và các kết quả dự đoán trên <code>test set</code> của các <code>base models</code> được sử dụng như là <code>test set</code> (<code>ensemble test set</code>) của <code>blending model</code>.</li>
                        </ul>
                    </li>
                    <li>Bước 6: Train và đánh giá <code>blending model</code> sử dụng <code>ensemble train set</code> và <code>ensemble test set</code>.</li>
                </ul>
                <p>Code minh họa ý tưởng:</p>
                <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># build two models, decision tree and knn, on the train set in order to make predictions on the validation set.</span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">val_pred_1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">test_pred_1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">val_pred_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">val_pred_1</span><span class="p">)</span>
<span class="n">test_pred_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_pred_1</span><span class="p">)</span>

<span class="n">model_2</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">val_pred_2</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">test_pred_2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">val_pred_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">val_pred_2</span><span class="p">)</span>
<span class="n">test_pred_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_pred_2</span><span class="p">)</span>

<span class="c1"># Combining the meta-features and the validation set, a logistic regression model is built to make predictions on the test set.</span>
<span class="n">df_val</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">x_val</span><span class="p">,</span> <span class="n">val_pred_1</span><span class="p">,</span><span class="n">val_pred_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">x_test</span><span class="p">,</span> <span class="n">test_pred1</span><span class="p">,</span><span class="n">test_pred_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">df_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
                <p><em><strong>3.3 Bagging</strong></em></p>
                <p><code>Bagging</code> (<em>Bootstrap Aggregating</em>) khác với hai kỹ thuật trên ở chỗ, nó sử dụng chung 1 thuật toán cho tất cả các <code>base models</code>. Tập dataset sẽ được chia thành các phần khác nhau (<code>bags</code>) và mỗi
                    <code>base model</code> sẽ được train trên mỗi bag đó.</p>
                <p>Các bước thực hiện của <code>bagging</code> như sau:</p>
                <ul>
                    <li>Bước 1: Chia tập dữ liệu ban đầu thành nhiều phần khác nhau (<code>bags</code>).</li>
                    <li>Bước 2: Tạo các <code>base models</code> (<em>weak learner</em>) và train chúng trên các bags. Các <code>base model</code> được train song song và độc lập với nhau.</li>
                    <li>Bước 3: Kết quả dự đoán cuối cùng được quyết định bằng cách kết hợp kết quả từ các <code>base models</code>.</li>
                </ul>


                <div style="text-align:center">
                    <img src="/bagging_1.png">
                </div>


                <p><em><strong>3.4 Boosting</strong></em></p>
                <p>Nếu như các <code>base models</code> được train độc lập với nhau trong phương pháp <code>bagging</code>, thì ở phương pháp <code>boosting</code>, chúng lại được train một cách tuần tự. <code>Base model</code> sau được train dựa theo kết
                    quả của <code>base model</code> trước đó để cố gắng sửa những lỗi sai tồn tại ở model này.</p>
                <p>Các bước tiến hành như sau:</p>
                <ul>
                    <li>Bước 1: Tạo một tập dữ liệu con (tập A) từ tập dữ liệu ban đầu (tập D).</li>
                    <li>Bước 2: Gán cho mỗi điểm dữ liệu trong tập A một trọng số w có giá trị giống nhau.</li>
                    <li>Bước 3: Tạo một <code>base model</code> X và train trên tập A.</li>
                    <li>Bước 4: Sử dụng model X để dự đoán trên toàn bộ tập D.</li>
                    <li>Bước 5: Tính toán sai số dự đoán dựa vào kết quả dự đoán và kết quả thực tế.</li>
                    <li>Bước 6: Gán giá trị w cao hơn cho những điểm dữ liệu bị dự đoán sai.</li>
                    <li>Bước 7: Lặp lại bước 1,2,3,4,5,6 đối với <code>base model</code> mới, Y.</li>
                    <li>Bước 8: Model cuối cùng (<code>boosting model</code>) sẽ là trung bình có trọng số của tất cả các <code>base models</code>.</li>
                </ul>
                <p>Mỗi <code>base model</code> được gọi là một <code>weak learner</code>. Chúng sẽ không hoạt động tốt trên toàn bộ tập D, nhưng khi kết hợp nhiều <code>weak learners</code> ta được một <code>strong learner</code>. <code>Strong learner</code>                    này chắc chắn sẽ hiệu quả trên tập D. Ta nói, các <code>weak learners</code> đã <code>boost performance</code> cho <code>strong learner</code>.</p>
                <p><code>Bagging</code> và <code>Boosting</code> là 2 kỹ thuật quan trọng, hiệu quả. Có một số thuật toán đã được phát triển dựa trên nền tảng của chúng. Đặc biệt là thuật toán XGBoost. Trong bài tiếp theo, chúng ta sẽ đi chi tiết hơn về
                    các thuật toán này.</p>
                <p>Mời các bạn đón đọc!</p>
                <p><em>Toàn bộ source code của bài này các bạn có thể tham khảo trên github cá nhân của mình tại <a href="https://github.com/tiensu/xgboost-algorithm/tree/master/ensemble_learning">github.</a></em></p>
                <p>Bài viết có tham khảo tại <a href="https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models">đây</a>.</p>

            </div>
            <div class="info post_meta">
                <time datetime=2020-08-20T00:00:00Z class="date">Thursday, August 20, 2020</time>

                <ul class="tags">

                    <li> <a href="https://tiensu.github.io/tags/ai">AI</a> </li>

                    <li> <a href="https://tiensu.github.io/tags/ml">ML</a> </li>

                    <li> <a href="https://tiensu.github.io/tags/ensemble-learning">Ensemble Learning</a> </li>

                    <li> <a href="https://tiensu.github.io/tags/xgboost">XGBoost</a> </li>

                </ul>


            </div>
            <div class="clearfix"></div>
        </article>

        <div class="other_posts">

            <a href="https://tiensu.github.io/posts/xgboost/02_xgboost-model-serial-introduction/" class="prev">XGBoost - Giới thiệu chuỗi bài viết về thuật toán XGBoost</a>


            <a href="https://tiensu.github.io/posts/xgboost/04_comprehensive_guide_to_ensemble_model_2/" class="next">XGBoost - Bài 2: Toàn cảnh về Ensemble Learning - Phần 2</a>

        </div>
        <aside id="comments">
        </aside>


    </section>

    <a id="back_to_top" title="Go To Top" href="#">
        <span>
    <svg viewBox="0 0 24 24">
      <path fill="none" d="M0 0h24v24H0z"></path>
      <path d="M12 2L4.5 20.29l.71.71L12 18l6.79 3 .71-.71z"></path>
    </svg>
  </span>
    </a>

    <footer id="footer">
        <p>
            <span>&copy; 2020 <a href="https://tiensu.github.io/" title="ML in Practical">ML in Practical</a> </span>
            <span>Built with <a rel="nofollow" target="_blank" href="https://gohugo.io">Hugo</a></span>
            <span>Theme by <a rel="nofollow" target="_blank" href="https://github.com/wayjam/hugo-theme-mixedpaper">WayJam</a></span>
        </p>
        <script src="https://tiensu.github.io/js/main.min.8b182175f5874aeed0acc0979345c98d4bde22208ec4f36cc1d6e3102acb4b10.js" integrity="sha256-ixghdfWHSu7QrMCXk0XJjUveIiCOxPNswdbjECrLSxA=" crossorigin="anonymous" async></script>
    </footer>

</body>

</html>