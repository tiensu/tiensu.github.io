<!DOCTYPE html>
<html lang="en-us">
    <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="format-detection" content="telephone=no" />

  <title>
    XGBoost - Bài 8: Cấu hình Early_Stopping cho XGBoost model | ML in Practical
  </title>

  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/manifest.json" />
  <meta name="theme-color" content="#ffffff" />

  
  <link
    rel="stylesheet"
    href="https://unpkg.com/modern-normalize@0.6.0/modern-normalize.css"
  />

  
  
  
  
  <link rel="stylesheet" href="https://tiensu.github.io/style.min.f7761d111b74dd5c07f0111decee92938c12abc42e0fd319e1a07483e248b54e.css" integrity="sha256-93YdERt03VwH8BEd7O6Sk4wSq8QuD9MZ4aB0g&#43;JItU4=" />

  
  
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-180180568-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>

  
</head>

    <body>
        <header id="header">
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-180180568-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>

  <div class="header_container">
    <h1 class="sitetitle">
      <a href="https://tiensu.github.io/" title="ML in Practical">ML in Practical</a>
    </h1>
    <nav class="navbar">
      <ul>
        <li><a href="https://tiensu.github.io/">Home</a></li>
        
          <li>
            <a href="/about/">
              
              <span>About</span>
            </a>
          </li>
        
          <li>
            <a href="/tags/">
              
              <span>Tags</span>
            </a>
          </li>
        
          <li>
            <a href="/archives/">
              
              <span>Archives</span>
            </a>
          </li>
        
        <li class="hide-sm"><a href="https://tiensu.github.io/index.xml" type="application/rss+xml">RSS</a></li>
      </ul>
    </nav>
  </div>
</header>

        
<section id="main">
  <article class="post content">
    <h2 class="title">XGBoost - Bài 8: Cấu hình Early_Stopping cho XGBoost model</h2>
    <div class="post_content">
      <p><a href="https://en.wikipedia.org/wiki/Overfitting">Overfitting</a> vẫn luôn là một vấn đề làm đau đầu những kỹ sư AI. Trong bài viết này chúng ta sẽ cùng tìm hiểu cách thức monitor (<em>giám sát</em>) performance (<em>hiệu năng</em>) của XGBoost model trong suốt quá trình train. Từ đó cấu hình <code>early stopping</code> để  quyết định khi nào thì nên dừng lại quá trình này để tránh hiện tượng <code>overfitting</code>.
Bài viết gồm 2 phần:</p>
<ul>
<li>Monitor hiệu năng của XGBoost model thông qua <code>learning curve</code> (<em>đường cong học tập</em>).</li>
<li>Cấu hình <code>early stopping</code>.</li>
</ul>
<p><strong>1. Giám sát hiệu năng của XGBoost model</strong></p>
<p>Để  monitor porformance của XGBoost model, ta cần cung cấp cả <code>train set</code>, <code>test set</code> và một metric (<em>chỉ tiêu đánh giá</em>) khi train model (<em>gọi hàm <code>model.fit()</code></em>). Ví dụ, để tính toán <code>error</code> metric trên tập <code>test set</code>, sử dụng code snippet sau:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&#34;error&#34;</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p>XGBoost model hỗ trợ một số metric như sau:</p>
<ul>
<li><strong>rmse</strong>: root mean squared error.</li>
<li><strong>mae</strong>: mean absolute error.</li>
<li><strong>logloss</strong>: binary logarithmic loss.</li>
<li><strong>mlogloss</strong>: multiclass log loss (cross entropy).</li>
<li><strong>error</strong>: classification error.</li>
<li><strong>auc</strong>: area under ROC curve.
Danh sách đầy đủ các metrics, các bạn có thể xem tại <a href="http://XGBoost.readthedocs.io/en/latest/parameter.html">đây</a>.</li>
</ul>
<p>Code dưới đây minh hoạ việc monitor performance trong quá trình train một XGBoost model trên tập dữ liệu <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabet">Pima Indians onset of diabetes</a>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># monitor training performance</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">loadtxt</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="c1"># load data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;pima-indians-diabetes.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
<span class="c1"># split data into X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>
<span class="c1"># split data into train and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="c1"># fit model on training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&#34;error&#34;</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># make predictions for test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># evaluate predictions</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Accuracy: </span><span class="si">%.2f%%</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
</code></pre></div><p>Ở đây, ta sử dụng 67% dữ liệu cho việc train, 33% còn lại cho viêc đánh giá model. <code>Error</code> metric được tính toán tại cuối mỗi vòng lặp (<em>sau khi mỗi <code>boosted tree</code> được thêm vào model</em>). Cuối cùng, độ chính xác của model được in ra.</p>
<p>Kết quả hiển thị trên màn hình như sau:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">[</span><span class="mi">0</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.28347</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25984</span>
<span class="p">[</span><span class="mi">2</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25591</span>
<span class="p">[</span><span class="mi">3</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.24803</span>
<span class="p">[</span><span class="mi">4</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.24409</span>
<span class="p">[</span><span class="mi">5</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.24803</span>
<span class="p">[</span><span class="mi">6</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25591</span>
<span class="p">[</span><span class="mi">7</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.24803</span>
<span class="p">[</span><span class="mi">8</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25591</span>
<span class="p">[</span><span class="mi">9</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.24409</span>
<span class="o">...</span>
<span class="p">[</span><span class="mi">89</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.26378</span>
<span class="p">[</span><span class="mi">90</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.27165</span>
<span class="p">[</span><span class="mi">91</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.26772</span>
<span class="p">[</span><span class="mi">92</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.27165</span>
<span class="p">[</span><span class="mi">93</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.26378</span>
<span class="p">[</span><span class="mi">94</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.27165</span>
<span class="p">[</span><span class="mi">95</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.26378</span>
<span class="p">[</span><span class="mi">96</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25984</span>
<span class="p">[</span><span class="mi">97</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.26378</span>
<span class="p">[</span><span class="mi">98</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25984</span>
<span class="p">[</span><span class="mi">99</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">error</span><span class="p">:</span><span class="mf">0.25984</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">74.02</span><span class="o">%</span>
</code></pre></div><p>Quan sát kết quả ta thấy performance của model không thay dổi quá nhiều trong suốt quá trình train. Thậm chí đến cuối quá trình, performance còn kém hơn so với nửa đầu.</p>
<p>Để có cái nhìn tường minh hơn, hãy thể hiện performance của model trên đồ thị.
Ta sẽ monitor performace của model trên cả <code>train set</code> và <code>test set</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&#34;error&#34;</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p>Performance của model trên mỗi tập <code>evaluation set</code> được lưu bởi model sau khi train kết thúc. Để truy cập giá trị performace này, sử dụng hàm <code>model.evals_result()</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evals_result</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div><p>Kết quả in ra sẽ giống như sau:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">{</span>
<span class="s1">&#39;validation_0&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.259843</span><span class="p">,</span> <span class="mf">0.26378</span><span class="p">,</span> <span class="mf">0.26378</span><span class="p">,</span> <span class="o">...</span><span class="p">]},</span>
<span class="s1">&#39;validation_1&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.22179</span><span class="p">,</span> <span class="mf">0.202335</span><span class="p">,</span> <span class="mf">0.196498</span><span class="p">,</span> <span class="o">...</span><span class="p">]}</span>
<span class="p">}</span>
</code></pre></div><p><code>validation_0</code> và <code>validation_1</code> theo thứ tự tương ứng với hai tập <code>validation set</code> mà ta đã định nghĩa trong tham số <code>eval_set</code> khi gọi hàm <code>fit()</code>.</p>
<p><code>Error</code> metric được truy cập như sau:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">]</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">]</span>
</code></pre></div><p>Thêm nữa, bạn có thể lựa chọn nhiều metrics để đánh giá model bằng cách cung cấp một mảng các giá trị metric tới tham số <code>eval_metric</code> của hàm <code>fit()</code>. Giá trị của các metric thu được sau đó đươc thể hiện trên đồ thị, gọi là <code>learning curve</code>.</p>
<p>Code đầy đủ dưới đây minh họa việc thu thập giá tị của các metrics và thể hiện trên <code>learning curve</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># plot learning curve</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">loadtxt</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># load data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;pima-indians-diabetes.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
<span class="c1"># split data into X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>
<span class="c1"># split data into train and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="c1"># fit model on training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;error&#34;</span><span class="p">,</span> <span class="s2">&#34;logloss&#34;</span><span class="p">],</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span>
<span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># make predictions for test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># evaluate predictions</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Accuracy: </span><span class="si">%.2f%%</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
<span class="c1"># retrieve performance metrics</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evals_result</span><span class="p">()</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">])</span>
<span class="n">x_axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>
<span class="c1"># plot log loss</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;logloss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">][</span><span class="s1">&#39;logloss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Log Loss&#39;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;XGBoost Log Loss&#39;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># plot classification error</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Classification Error&#39;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;XGBoost Classification Error&#39;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>Chạy code trên, <code>error</code> và <code>logloss</code> metric trên cả 2 tập <code>train set</code> và <code>test set</code> được in ra. Ta có thể bỏ qua điều này bằng cách truyền giá trị <code>False</code> (<em>giá trị mặc định</em>) cho tham sô <code>verbose</code> khi gọi hàm <code>fit()</code>. Hai đồ thị được tạo ra. Đồ thị đầu tiên thể hiện <code>logloss</code> của XGBoost model đối với mỗi <code>epoch</code> (<em>iteration</em>) trong quá trình train.
<figure>
    <img src="/plot_learning_curve_1.png" width="1200"/> 
</figure>
</p>
<p>Đồ thị thứ 2 hiển thị <code>error</code> metric của mỗi epoch.
<figure>
    <img src="/plot_learning_curve_2.png" width="1200"/> 
</figure>
</p>
<p>Quan sát cả 2 đồ thị trên ta có một nhận xét rằng, nếu dừng train sớm hơn tại epoch &lt; 100 thì performace của model sẽ tốt hơn. Đây chính là tiền đề của kỹ thuật <code>early stopping</code> mà chúng ta sẽ tìm hiểu ngay sau đây.</p>
<p><strong>2. Cấu hình <code>early stopping</code> cho XGBoost model</strong></p>
<p><code>Early stopping</code> là một kỹ thuật khá phổ biến áp dụng cho các ML model phức tạp để tránh hiện tượng <code>overfitting</code>. Nó làm việc bằng cách monitor performance của model trên tập <code>test set</code> trong suốt quá trình train và buộc quá trình này dừng lại một khi performance của model không được cải thiện sau một số epochs nhất định.</p>
<p>Trên đồ thị <code>learning curve</code>, điểm bắt đầu <code>overfitting</code> là điể mà tại đó performace của model trên tập <code>test set</code> bắt đầu giảm trong khi performance của model trên tập <code>train set</code> vẫn tiếp tục tăng.</p>
<p>Để cấu hình <code>early stopping</code> cho XGBoost model, cần cung cấp thêm giá trị cho tham số <code>early_stopping_rounds</code> khi gọi hàm <code>fit()</code>. Ý nghĩa của nó là chỉ ra số lượng epochs mà quá trình húân luyện trải qua mà performance không có sự cải thiện nào.</p>
<p>Ví dụ:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&#34;logloss&#34;</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p>Nếu có nhiều <code>evaluation sets</code> hoặc nhiều metrics được cung cấp, <code>early stopping</code> sẽ sử dụng cái cuối cùng trong danh sách.</p>
<p>Code đầy đủ cấu hình <code>early stopping</code> như bên dưới:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># early stopping</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">loadtxt</span>
<span class="kn">from</span> <span class="nn">XGBoost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="c1"># load data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;pima-indians-diabetes.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
<span class="c1"># split data into X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>
<span class="c1"># split data into train and test sets</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.33</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="c1"># fit model on training data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&#34;logloss&#34;</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># make predictions for test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># evaluate predictions</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Accuracy: </span><span class="si">%.2f%%</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
</code></pre></div><p>Kết quả chạy code:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">[</span><span class="mi">0</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.60491</span>
<span class="n">Will</span> <span class="n">train</span> <span class="n">until</span> <span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span> <span class="n">hasn</span><span class="s1">&#39;t improved in 10 rounds.</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.55934</span>
<span class="p">[</span><span class="mi">2</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.53068</span>
<span class="p">[</span><span class="mi">3</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.51795</span>
<span class="p">[</span><span class="mi">4</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.51153</span>
<span class="p">[</span><span class="mi">5</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.50935</span>
<span class="p">[</span><span class="mi">6</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.50818</span>
<span class="p">[</span><span class="mi">7</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.51097</span>
<span class="p">[</span><span class="mi">8</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.51760</span>
<span class="p">[</span><span class="mi">9</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.51912</span>
<span class="p">[</span><span class="mi">10</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.52503</span>
<span class="p">[</span><span class="mi">11</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.52697</span>
<span class="p">[</span><span class="mi">12</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.53335</span>
<span class="p">[</span><span class="mi">13</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.53905</span>
<span class="p">[</span><span class="mi">14</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.54546</span>
<span class="p">[</span><span class="mi">15</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.54613</span>
<span class="p">[</span><span class="mi">16</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.54982</span>
<span class="n">Stopping</span><span class="o">.</span> <span class="n">Best</span> <span class="n">iteration</span><span class="p">:</span>
<span class="p">[</span><span class="mi">6</span><span class="p">]</span>	<span class="n">validation_0</span><span class="o">-</span><span class="n">logloss</span><span class="p">:</span><span class="mf">0.50818</span>

<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">74.41</span><span class="o">%</span>
</code></pre></div><p>Quá trình train model dừng lại ở epoch 16 (<em>gần với những gì mà chúng ta phán đoán dựa trên đồ thị learning curve</em>) và model đạt được metric thấp nhất tại epoch 6. Việc chọn giá trị của tham số <code>early_stopping_rounds</code> thường dựa vào quan sát trên đồ thị <code>learning curve</code>. Nếu bạn không biết thì có thể chọn giá trị mặc định là 10.</p>
<p><strong>3. Kết luận</strong></p>
<p>Trong bài viết này, chúng ta đã tìm hiểu cách monitor performance của XGBoost model trong quá trình train và cấu hình <code>early stopping</code> để hạn chế hiện tượng <code>overfitting</code> của model.</p>
<p>Ở bài viết tiếp theo chúng ta sẽ tìm hiểu cách cấu hình XGBoost model để tận dụng hết tài nguyên của phần cứng khi train model và khi sử model để dự đoán. Hãy cùng đón đọc! :)</p>
<p><em>Toàn bộ source code của bài này các bạn có thể tham khảo trên github cá nhân của mình tại <a href="https://github.com/tiensu/XGBoost-algorithm/tree/master/early-stopping">github.</a></em></p>
<p>Bài viết có tham khảo tại <a href="https://machinelearningmastery.com/XGBoost-with-python/">tham khảo</a>.</p>

    </div>
    <div class="info post_meta">
      <time datetime=2020-09-30T00:00:00Z class="date">Wednesday, September 30, 2020</time>
      
        <ul class="tags">
        
          <li> <a href="https://tiensu.github.io/tags/ai">AI</a> </li>
        
          <li> <a href="https://tiensu.github.io/tags/ml">ML</a> </li>
        
          <li> <a href="https://tiensu.github.io/tags/xgboost">XGBoost</a> </li>
        
        </ul>
      
      
    </div>
    <div class="clearfix"></div>
  </article>
  
    <div class="other_posts">
      
      <a href="https://tiensu.github.io/posts/xgboost/feature-selection/" class="prev">Bài 7: Lựa chọn features cho XGBoost model</a>
      
      
      <a href="https://tiensu.github.io/posts/xgboost/multithreading-xgboost/" class="next">Bài 9: Cấu hình Multithreading cho XGBoost model</a>
      
    </div>
    <aside id="comments">
</aside>

  
</section>

        <a id="back_to_top" title="Go To Top" href="#">
  <span>
    <svg viewBox="0 0 24 24">
      <path fill="none" d="M0 0h24v24H0z"></path>
      <path d="M12 2L4.5 20.29l.71.71L12 18l6.79 3 .71-.71z"></path>
    </svg>
  </span>
</a>

        <footer id="footer">
  <p>
    <span>&copy; 2020 <a href="https://tiensu.github.io/" title="ML in Practical">ML in Practical</a> </span>
    <span>Built with <a rel="nofollow" target="_blank" href="https://gohugo.io">Hugo</a></span>
    <span>Theme by <a rel="nofollow" target="_blank" href="https://github.com/wayjam/hugo-theme-mixedpaper">WayJam</a></span>
  </p>
  <script src="https://tiensu.github.io/js/main.min.8b182175f5874aeed0acc0979345c98d4bde22208ec4f36cc1d6e3102acb4b10.js" integrity="sha256-ixghdfWHSu7QrMCXk0XJjUveIiCOxPNswdbjECrLSxA=" crossorigin="anonymous" async></script>
</footer>

    </body>
</html>
