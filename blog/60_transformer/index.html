<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8">
  <title>SuNT&#39;s Blog | AI in Practical</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="This is meta description">
  <meta name="author" content="SuNT">
  <meta name="generator" content="Hugo 0.68.3" />

  <!-- plugins -->
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/venobox/venobox.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/css/override.css">
  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="https://tiensu.github.io/scss/style.min.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="https://tiensu.github.io/images/favicon.png " type="image/x-icon">
  <link rel="icon" href="https://tiensu.github.io/images/favicon.png " type="image/x-icon">

  <!-- google analitycs -->
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'Your ID', 'auto');
    ga('send', 'pageview');
  </script>

</head><body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0">
      <a class="navbar-brand mobile-view" href="https://tiensu.github.io/"><img class="img-fluid"
          src="https://tiensu.github.io/images/logo3.jpg" alt="SuNT&#39;s Blog | AI in Practical"></a>
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.facebook.com/tiensunguyen2103"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.linkedin.com/in/su-nguyen-tien-aws%C2%AE-5ba74ba6/"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <a class="navbar-brand mx-auto desktop-view" href="https://tiensu.github.io/"><img class="img-fluid"
            src="https://tiensu.github.io/images/logo3.jpg" alt="SuNT&#39;s Blog | AI in Practical"></a>

        <ul class="navbar-nav">
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://tiensu.github.io/about">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://tiensu.github.io/blog">Post</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://tiensu.github.io/contact">Contact</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search pl-lg-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://tiensu.github.io//search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/rnn"
          class="text-primary">R n n</a>
        
        <a href="/categories/lstm"
          class="text-primary">L s t m</a>
        
        <a href="/categories/attention"
          class="text-primary">Attention</a>
        
        <a href="/categories/transformer"
          class="text-primary">Transformer</a>
        
        <h2>Transformers - Nhưng không phải là kẻ hủy diệt &hellip;</h2>
        <div class="mb-3 post-meta">
          <span>By SuNT</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>25 April 2021</span>
          
        </div>
        
        <img src="https://tiensu.github.io/images/featured-post/transformers.jpeg" class="img-fluid w-100 mb-4" alt="Transformers - Nhưng không phải là kẻ hủy diệt &hellip;">
        
        <div class="content mb-5">
          <p>Nếu bạn là dân ngoại đạo, bạn cũng có thể đã từng nghe về <a href="https://en.wikipedia.org/wiki/Transformers_(film_series)">Transformers</a>. Đó là một bộ phim bom tấn, liên tục lập kỷ lục phòng vé tại thời điểm nó ra mắt. Tuy nhiên, <em>Transformers</em> mình muốn nói ở đầy là một AI model. Được giới thiệu lần đầu vào năm 2017 trong bài báo <a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a>, cũng như bộ phim kia, nó cũng lập tức gây chấn động cộng động NLP lúc bấy giờ bởi hiệu năng của nó hơn hẳn so với các kiến trúc mô hình tồn tại trước đó trong các thử nghiệm được công bố.</p>
<p><strong>1. So sánh Transformers và họ hàng nhà RNN (LSTM, GRU)</strong></p>
<p>Đầu tiên, chúng ta thử so sánh Transformers với họ hàng RNN để thấy được ưu điểm của nó, và hiểu tại sao nó lại được yêu mến đến vậy.</p>
<p>Như chúng ta đã biết, kiến trúc Encoder-Decoder với RNN truyền thống tồn tại 2 nhược điểm:</p>
<ul>
<li>Không có khả năng tận dụng hết thông tin ngữ nghĩa của Input và Targer Sequence, đặc biệt là trong trường hợp Input Sequence có chiều dài lớn (<em>Với cơ chế Attention, khả năng này có tốt hơn một chút nhưng vẫn chưa đủ</em>).</li>
<li>Vì phải xử lý tuần tự từng TimeStep một nên thời gian tính toán rất lâu.</li>
</ul>
<p>Transformers giải quyết được 2 nhược điểm đó bằng cách:</p>
<ul>
<li>Sử dụng cơ chế Self-Attention (<em>nhiều tầng Self-Attentions</em>) để nắm bắt tốt hơn thông tin ngữ nghĩa của Input và Targer Sequence.</li>
<li>Xử lý song song tất cả các TimeStep cùng một lúc &ndash;&gt; Giảm được rất nhiều thời gian tính toán.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/rnn_transformers_compare.png">
</div>

</li>
</ul>
<p><strong>2. Kiến trúc và thành phần của Transformers</strong></p>
<p>Transformer tỏ ra vượt trội trong việc xử lý dữ liệu văn bản vốn có tính chất tuần tự. Nó lấy một chuỗi văn bản làm đầu vào và tạo ra một chuỗi văn bản khác. Ví dụ như bài toán Machine Translation hay Text Summarization.</p>
<p>Về thành phần cấu tạo, Transformers bao gồm một nhóm các bộ Encoders (<em>Encoder stack</em>) và một nhóm các bộ Decoder (<em>Decoder stack</em>). Ngoài ra còn có các thành phần Embedding, Encoding, Mask, &hellip; khác để xử lý dữ liệu đầu vào và đầu ra.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_architecture.png">
</div>

</p>
<p><em><strong>2.1 Positional Encoder</strong></em></p>
<p>Việc xử lý đồng thời tất cả cá từ trong câu một lượt mang lại khả năng tính toán nhanh chóng cho Transformers, nhưng nó lại vô tình làm mất thông tin về vị trí của các từ trong câu đó. Để khắc phục vấn đề này, thông tin về vị trí của từ được mã hóa thành Positional Encoding (<em>PE</em>) vector để làm đầu vào cho Transformers.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/positional_encoding.png">
</div>

</p>
<p>PE được tính như sau:


<div style="text-align-last:center">
   <p>$PE_{(pos,2i)} = sin(\frac{pos}{1000^{\frac{2i}{d}}})$</p>
   <p>$PE_{(pos,2i+1)} = cos(\frac{pos}{1000^{\frac{2i}{d}}})$</p>
</div>

</p>
<p>Trong đó, $pos$ là vị trí của từ trong câu, còn $i$ là chỉ số của các phần tử trong PE vector, $d$ là số chiều của Work/Token Embedding (<em>cũng bằng với kích thước của PE</em>).


<div style="text-align:center">
   <img style="height:auto" src="/images/post/positional_encoding_1.png">
</div>

</p>
<p>Trong khi $d$ cố định thì $pos$ và $i$ thay đổi. PE cuối cùng là tổng hợp của tất cả các PE với sự thay đổi của $pos$ và $i$ đó.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/positional_encoding_pos.png">
</div>

</p>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/positional_encoding_i.png">
</div>


<p>Chi tiết thêm về Positional Encoding, các bạn có thể tham khảo tại <a href="https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3">đây</a>.</p>
<p><em><strong>2.2 Masking</strong></em></p>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking.png">
</div>


<p>Mục đích chính của Masking là che giấu (<em>Mask</em>) đi phần thông tin của Token phía sau, chỉ cho phép Decoder sử dụng thông tin của Token hiện tại và trước đó khi tạo Ouput. Ví dụ như trong một kỳ thi, ta cần phải che giấu đáp án đi, chỉ cho phép thí sinh sử dụng kiến thức của họ để làm bài.</p>
<p>Xem xét cách tính Output của Self-Attention như hình dưới đây:


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking.jpeg">
</div>

</p>
<p>Có 4 bước, chúng ta sẽ đi chi tiết mỗi bước.</p>
<ul>
<li><em>Bước 1</em>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_1.png">
</div>

</li>
</ul>
<p>Ma trận Query (<em>Q</em>) được tạo từ Input (<em>X</em>) và ma trận trọng số của Q ($W^Q$). Tương tự cho Key (<em>K</em>) và Value (<em>V</em>).</p>
<p>X có kích thước là (2,4), trong đó 2 là chiều dài của Input Sequence (<em>số từ trong câu</em>), 4 là số chiều của Word Embedding của 1 từ.</p>
<p>$W^Q$ có kích thước là (4,4), trong đó 4 là số chiều của Word Embedding của 1 từ, 4 là do chúng ta giả sử $W^Q$ là ma trận vuông cho dễ xử lý. Thực tế có thể phức tạp hơn.</p>
<p>Kết quả, các ma trận Q, V, K có kích thước (2, 4).</p>
<ul>
<li><em>Bước 2</em>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_2.png">
</div>

</li>
</ul>
<p>Đây chính là công thức tính Output của Self-Attention.</p>
<ul>
<li><em>Bước 3</em>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_3.png">
</div>

</li>
</ul>
<p>Ta biểu diễn ma trận $I = Q \times K^T$ bởi các giá trị A, B, C, D.
Nhận thấy rằng, A chỉ phụ thuộc vào Embedding Token ở vị trí đầu tiên: $A = q_1 \times k_1 = x_1*W^Q \times k_1$).</p>
<p>Trong khi đó, B phụ thuộc vào Embedding ở vị trí thứ nhất và thứ hai: ($B = q_1 \times k_2 = x_1<em>W^A \times x_2</em>W^K$).</p>
<p>($x_1, x_2$ <em>là các Embedding của Token thứ nhất và thứ hai</em>).</p>
<ul>
<li><em>Bước 4</em>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_4.png">
</div>

</li>
</ul>
<p>Làm tương tự cho ma trận F. Ta cũng nhận thấy B&rsquo; phụ thuộc vào Embedding Token của cả hai vị trí 1 và 2. Để ngăn chặn điều này, ta thêm vào Mask như sau:


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_5.png">
</div>

</p>
<p>Ở đó:


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_6.png">
</div>




<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_7.png">
</div>

</p>
<p>Ta được:


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_8.png">
</div>

</p>
<p>Và cuối cùng là:


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_masking_9.png">
</div>

</p>
<p>Như vậy, sau khi thêm Mask vào thì Output F của Decoder đã ko còn xuất hiện thành phần Embedding Token ở vị trí số 2.</p>
<p><em><strong>2.3 Scaled Dot-Product Attention</strong></em></p>
<p>Đây chính các phép tính toán của Self-Attention.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/scaled_dot_product.png">
</div>

</p>
<p>Lần lượt từng bước như sau:</p>
<ul>
<li>
<p><em>Matmul -</em> phép toán Matrix Dot-Product giữa ma trận Query và chuyển vị của ma trận Key.


<div style="text-align-last:center">
   <p>$MatMul(Q,K) = Q.K^T$</p>
</div>

</p>
</li>
<li>
<p><em>Scale -</em> Ouput của phép toán Dot-Product có thể là một giá trị rất lớn, có thể làm rối loạn hoạt động của hàm Softmax. Do vậy, ta Scale chúng bằng cách chia cho hệ số $\sqrt(d_k)$.</p>
</li>
<li>
<p><em>Mask -</em> như đã đề cập ở mục 2.2.</p>
</li>
<li>
<p><em>Softmax -</em> Đưa giá trị về một phân phối xác suất trong khoảng [0,1].


<div style="text-align-last:center">
   <p>$Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt(d_k)})V$</p>
</div>

</p>
</li>
</ul>
<p><em><strong>2.4 Multi-Head Self-Attention</strong></em></p>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/multi-head-self-attention_2.png">
</div>


<p>Xem lại bài <a href="https://tiensu.github.io/blog/59_self-attention/">trước</a>.</p>
<p><em><strong>2.5 Point-Wise Feed Forward Network and Residual Dropout</strong></em></p>


<div style="text-align:center">
   <img style="height:auto" src="/images/post/residual.png">
</div>


<p>Point-Wise Feed Forward Network Block, về cơ bản là một phép biến đổi tuyến tính hai lớp được sử dụng giống nhau trong toàn bộ kiến trúc mô hình, thường là sau các khối Attention.</p>
<p>Để áp dụng Regularization, một Dropout được áp dụng tại đầu ra của mỗi Sub-layer, trước khi nó được đưa vào làm Input cho Sub-layer tiếp theo.</p>
<p><strong>3. Huấn luyện mô hình Transformers</strong></p>
<p>Dữ liệu huấn luyện bao gồm 2 thành phần: Input Sequence và Target Sequence. Quá trình huấn luyện diễn ra như sau:</p>
<ul>
<li><em>Bước 1 -</em> Input Sequence được biến đổi thành Embedding, cùng với Positional Encoding để đưa vào Encoder Stack.</li>
<li><em>Bước 2 -</em> Encoder Stack xử lý và đưa ra một Vector đại diện của Input Sequence, gọi là Context Vector. Vector này sau đó được đưa sang cho Decoder Stack.</li>
<li><em>Bước 3 -</em> Target Sequence được bổ sung thêm tiền tố START_ (*còn gọi là start-of-sentence token*), chuyển đổi thành Embedding, cùng với Positional Decoding, đưa vào Decoder Stack.</li>
<li><em>Bước 4 -</em> Decoder Stack xử lý, sinh ra một Vector đại diện của Target Sequence.</li>
<li><em>Bước 5 -</em> Output Layer chuyển Vector đại diện này một Output Sequence.</li>
<li><em>Bước 6 -</em> Transformers Loss Function so sánh Output Sequence với Target Sequence. Loss sẽ được sử dụng để sinh ra Gradients để cập nhật trọng số mô hình trong quá trình Back-propagation.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_train.png">
</div>

</li>
</ul>
<p>Cách thức huấn luyện như thế này còn được gọi với cái tên là <em>Teacher Forcing</em>. Target Sequence ở đây đóng vai trò là Teacher để Force mô hình hoạt động đúng như mong muốn. Cá nhân mình thấy, nó khá giống với phương pháp Supervise Learning mà chúng ta đã quen thuộc.</p>
<p><strong>4. Sử dụng mô hình Transformers để dự đoán (Inference)</strong>
3
Quá trình dự đoán của Transformers có một chút khác biệt so với quá trình huấn luyện của nó. Chúng ta chỉ có Input Sequence, không có Target Sequence. Mục đích của Inference là sinh ra Output Sequence từ Input Sequence.</p>
<p>Trong mô hình Seq2Seq, Output của Decoder Stack được sinh ra trong một vòng lặp, Ouput từ TimeStep trước được đưa vào làm Input của TimeStep tiếp theo. Vòng lặp kết thúc khi Output là Token kết thúc (<em>_END</em>). Còn trong mô hình Transformers, tại mỗi TimeStep, toàn bộ Output tại các thời điểm trước đó được đưa vào làm Input cho thời điểm tiếp theo, thay vì chỉ sử dụng Output cuối cùng.</p>
<p>Toàn bộ quá trình Inference diễn ra như sau:</p>
<ul>
<li><em>Bước 1 -</em> Input Sequence đuọc chuyển thành Embedding, cùng với Positional Decoding, đưa vào Encoder Stack.</li>
<li><em>Bước 2 -</em> Encoder Stack xử lý và tạo ra Context Vector. Vector này được chuyển sang cho Decoder Stack.</li>
<li><em>Bước 3 -</em> Phía Decoder Stack, sử dụng một Input Sequence rỗng (*chỉ có một Start Token - START_*), chuyển sang Embedding, cùng với Positional Encoding, đưa vào Decoder Stack.</li>
<li><em>Bước 4 -</em> Decoder Stack xử lý, cùng với Context Vector từ Encoder Stack, sinh ra Vector đại diện của Output Sequence.</li>
<li><em>Bước 5 -</em> Output Layer biến đổi Vector đại diện này thành Output Sequence.</li>
<li><em>Bước 6 -</em> Từ cuối cùng trong Output Sequence đặt vào vị trí thứ 2 (<em>sau Start Token</em>) của Input Sequence của Decoder Stack. Sau đó, Intput Sequence mới này lại được đưa vào Decoder Stack.</li>
<li><em>Bước 7 -</em> Lặp lại từ bước 4-6 cho đến khi bắt gặp từ cuối cùng trong Ouput Sequence là End Token (<em>_END</em>).


<div style="text-align-last:center">
   <img style="height:auto" src="/images/post/transformers_inference.png">
</div>

</li>
</ul>
<p><strong>5. Ứng dụng của Transformers</strong></p>
<p>Transformers được sử dụng rất rộng rãi ở hầu hết các bài toán trong lĩnh vực NLP. Với mỗi bài toán, chúng ta sẽ sử dụng một biến thể khác của Transformers.</p>
<ul>
<li>
<p><em>Language models -</em>
Đây là bài toán sinh ra từ mới cho câu (<em>sáng tác nhạc, làm thơ, viết truyện, &hellip;</em>). Ở đây, chỉ thành phần Encoder Stack của Transformers được sử dụng, như là một bộ trích xuất đặc trưng (<em>Sequence Embedding</em>) của Input Sequence. Đầu ra của Encoder Stack được đưa vào Language Model để cho ra một xác suất cho mỗi từ trong từ điển. Từ có xác suất cao nhất là kết quả cuối cùng.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_language_model.png">
</div>

</p>
</li>
<li>
<p><em>Text Classification -</em>
Đây là bài toán phân loại văn bản thành các chủ đề, nhãn, &hellip; khác nhau. Tương tự Language Model, chúng ta cũng chỉ sử dụng phần Encoder Stack cho ứng dụng này. Đầu ra của Encoder Stack được đưa vào bộ phân lớp, cho ra xác suất của từng nhãn. Nhãn có xác suất cao nhất sẽ được công nhận là kết quả chung cuộc.


<div style="text-align:center">
   <img style="height:auto" src="/images/post/transformers_classification.png">
</div>

</p>
</li>
<li>
<p><em>Seq2Seq models -</em>
Đây là lớp bài toán bao gồm Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, Speech Recognition, &hellip;</p>
</li>
</ul>
<p>Kiến trúc đầy đủ của Transformers được sử dụng trong các ứng dụng này.</p>
<p><strong>5. Kết luận</strong></p>
<p>Trong bài này, chúng ta đã cùng nhau tìm hiểu khá chi tiết về kiến trúc Transformers, cũng như các ưu/nhược điểm và ứng dụng của nó.</p>
<p>Ở bài tiếp theo, mình sẽ giới thiệu về của BERT, một <em>state of the art language model for NLP</em>. Mời các bạn đón đọc.</p>
<p><strong>6. Tham khảo</strong></p>
<ul>
<li><a href="https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853">Ketan Doshi</a></li>
<li><a href="https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452">Ketan Doshi</a></li>
<li><a href="https://datascience.stackexchange.com/questions/51065/what-is-the-positional-encoding-in-the-transformer-model">datascience</a></li>
<li><a href="https://towardsdatascience.com/transformers-explained-65454c0f3fa7">Rohan Jagtap</a></li>
<li><a href="https://medium.com/analytics-vidhya/masking-in-transformers-self-attention-mechanism-bad3c9ec235c">Samuel Kiebaum</a></li>
<li><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a></li>
</ul>

        </div>

        
        
      </div>
    </div>
  </div>
</section>



<footer>
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-12 text-center mb-5">
        <a href="https://tiensu.github.io/"><img src="https://tiensu.github.io/images/logo3.jpg" alt="SuNT&#39;s Blog | AI in Practical" style="height: auto"></a>
      </div>
               
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="tel:0869644890"><i
                class="ti-mobile mr-3 text-primary"></i>0869644890</a></li>
          
                     
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>Hanoi, Vietnam</li>
          
                     
          <li class="mb-3"><a class="text-dark" href="mailto:tiensunguyen2103@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>tiensunguyen2103@gmail.com</a>
          
          </li>
        </ul>
      </div>
      
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://www.facebook.com/tiensunguyen2103">Facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.linkedin.com/in/su-nguyen-tien-aws%C2%AE-5ba74ba6/">Linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/algorithm-optimization">Algorithm Optimization</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/attention">Attention</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/autoencoder">Autoencoder</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/bert">BERT</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/cnn">CNN</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/data-driff">Data Driff</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/data-science">Data Science</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/deep-learning">Deep Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/docker">Docker</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/ebook">Ebook</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/ensemble-learning">Ensemble Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/face-recognition">Face Recognition</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/image-classification">Image Classification</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/kubernetes">Kubernetes</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/lstm">LSTM</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/machine-learning">Machine Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/mlops">MLOps</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/neural-network">Neural Network</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/one-shot-learning">One Shot Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/project-management">Project Management</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/rnn">RNN</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/scalability">Scalability</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/siamese-network">Siamese Network</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/text-classification">Text Classification</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/transformer">Transformer</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/xgboost">XGBoost</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://tiensu.github.io/about">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://tiensu.github.io/blog">Post</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://tiensu.github.io/contact">Contact</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2021 <a href="tiensu.github.io">SuNT</a>. All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "https://tiensu.github.io/index.json"
</script>

<!-- JS Plugins -->

<script src="https://tiensu.github.io/plugins/jQuery/jquery.min.js"></script>

<script src="https://tiensu.github.io/plugins/bootstrap/bootstrap.min.js"></script>

<script src="https://tiensu.github.io/plugins/slick/slick.min.js"></script>

<script src="https://tiensu.github.io/plugins/venobox/venobox.min.js"></script>

<script src="https://tiensu.github.io/plugins/search/fuse.min.js"></script>

<script src="https://tiensu.github.io/plugins/search/mark.js"></script>

<script src="https://tiensu.github.io/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="https://tiensu.github.io/js/script.min.js"></script>




<script src="https://cdnjs.cloudflare.com/ajax/libs/js-cookie/2.2.1/js.cookie.min.js"></script>
<div id="js-cookie-box" class="cookie-box cookie-box-hide">
	This site uses cookies. By continuing to use this website, you agree to their use. <span id="js-cookie-button" class="btn btn-sm btn-primary ml-2">I Accept</span>
</div>
<script>
	(function ($) {
		const cookieBox = document.getElementById('js-cookie-box');
		const cookieButton = document.getElementById('js-cookie-button');
		if (!Cookies.get('cookie-box')) {
			cookieBox.classList.remove('cookie-box-hide');
			cookieButton.onclick = function () {
				Cookies.set('cookie-box', true, {
					expires:  2 
				});
				cookieBox.classList.add('cookie-box-hide');
			};
		}
	})(jQuery);
</script>


<style>
.cookie-box {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  text-align: center;
  z-index: 9999;
  padding: 1rem 2rem;
  background: rgb(71, 71, 71);
  transition: all .75s cubic-bezier(.19, 1, .22, 1);
  color: #fdfdfd;
}

.cookie-box-hide {
  display: none;
}
</style>
</body>
</html>