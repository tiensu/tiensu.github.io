<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8">
  <title>SuNT&#39;s Blog | AI in Practical</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="This is meta description">
  <meta name="author" content="SuNT">
  <meta name="generator" content="Hugo 0.80.0" />

  <!-- plugins -->
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/plugins/venobox/venobox.css ">
  
  <link rel="stylesheet" href="https://tiensu.github.io/css/override.css">
  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="https://tiensu.github.io/scss/style.min.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="https://tiensu.github.io/images/favicon.png " type="image/x-icon">
  <link rel="icon" href="https://tiensu.github.io/images/favicon.png " type="image/x-icon">

  <!-- google analitycs -->
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'Your ID', 'auto');
    ga('send', 'pageview');
  </script>

</head><body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0">
      <a class="navbar-brand mobile-view" href="https://tiensu.github.io/"><img class="img-fluid"
          src="https://tiensu.github.io/images/logo3.jpg" alt="SuNT&#39;s Blog | AI in Practical"></a>
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.facebook.com/tiensunguyen2103"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.linkedin.com/in/su-nguyen-tien-aws%C2%AE-5ba74ba6/"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <a class="navbar-brand mx-auto desktop-view" href="https://tiensu.github.io/"><img class="img-fluid"
            src="https://tiensu.github.io/images/logo3.jpg" alt="SuNT&#39;s Blog | AI in Practical"></a>

        <ul class="navbar-nav">
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://tiensu.github.io/about">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://tiensu.github.io/blog">Post</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="https://tiensu.github.io/contact">Contact</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search pl-lg-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://tiensu.github.io//search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/machine-learning"
          class="text-primary">Machine Learning</a>
        
        <a href="/categories/data-preparation"
          class="text-primary">Data Preparation</a>
        
        <h2>DP4ML - Outlier</h2>
        <div class="mb-3 post-meta">
          <span>By SuNT</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>30 June 2021</span>
          
        </div>
        
        <img src="https://tiensu.github.io/images/featured-post/77_data_cleaning.png" class="img-fluid w-100 mb-4" alt="DP4ML - Outlier">
        
        <div class="content mb-5">
          <p>Bài thứ 3 trong chuỗi các bài viết về chủ đề Data Preparation cho các mô hình ML. Trong bài này, chúng ta sẽ tìm hiểu về Outlier Data, mà tiếng việt của chúng ta gọi là <em>dữ liệu ngoại lệ</em>.</p>
<h3 id="1-outlier-data-là-gì">1. Outlier Data là gì?</h3>
<p>Đôi khi làm việc với dữ liệu, chúng ta bắt gặp các mẫu rất <em>lạ</em>, khác nhiều so với những mẫu khác trong cùng bộ dữ liệu. Sự khác nhau đó có thể là về kiểu dữ liệu, phạm vi giá trị, phân phối dữ liệu, &hellip; Số lượng những mẫu <em>lạ</em> thường không lớn, và chúng đó được gọi là Outlier Data, hay &ldquo;dữ liệu ngoại lệ&rdquo;. Việc tồn tại Outlier Data có thể gây nhiễu, làm cho việc mô hình hóa trở nên khó khăn hơn. Giải pháp xóa bỏ Outlier Data, trong hầu hết các trường hợp, giúp cải thiện đáng kể hiệu quả của các ML model.</p>
<p>Outlier Data được sinh ra do một trong các nguyên nhân chủ yếu sau:</p>
<ul>
<li>Xảy ra lỗi trong quá trình đo đạc, thu thập dữ liệu.</li>
<li>Dữ liệu bị hư hỏng (<em>currption</em>) trong quá trình lưu trữ hoặc chuyển đổi.</li>
<li>Dữ liệu bị tác động bởi các yếu tố ngẫu nhiên bên ngoài.</li>
</ul>
<p>Trong thực tế, không có định nghĩa chính xác của Outlier Data, bởi vì nó phụ thuộc vào bài toán cụ thể. Đối với bài toán này, đó có thể là Outlier Data, nhưng đối với bài toán kia, nó lại có thể là giá trị hợp lệ. Để quyết định chính xác, cần phải tham khảo thêm ý kiến của chuyên gia trong lĩnh vực đó.</p>
<h3 id="2-các-phương-pháp-nhận-diện-outlier-data">2. Các phương pháp nhận diện Outlier Data</h3>
<p>Trước khi tìm hiểu các phương pháp giúp nhận diện ra Outlier Data, chúng ta sẽ sinh ra một bộ dữ liệu giả để thực hành cho phần này.</p>
<p>Dữ liệu sinh ra bao gồm 10.000 số ngẫu nhiên được phân phối theo Gaussian, có Mean là 50 và STD là 5. Sẽ có một vài số trong tập dữ liệu này nằm ở khá xa so với Mean, chúng ta sẽ coi đó như là Outlier Data.</p>
<p>Code thực hiện như sau:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># generate gaussian data</span>
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> seed
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> randn
<span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> mean
<span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> std
<span style="color:#75715e"># seed the random number generator</span>
seed(<span style="color:#ae81ff">1</span>)
<span style="color:#75715e"># generate univariate observations</span>
data <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> randn(<span style="color:#ae81ff">10000</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">50</span>
<span style="color:#75715e"># summarize</span>
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39; mean=</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74"> stdv=</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> (mean(data), std(data)))
</code></pre></div><p>Chạy code trên ta có Output:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">mean<span style="color:#f92672">=</span><span style="color:#ae81ff">50.049</span> stdv<span style="color:#f92672">=</span><span style="color:#ae81ff">4.994</span>
</code></pre></div><h4 id="21-phương-pháp-sử-dụng-độ-lệch-chuẩn---std">2.1 Phương pháp sử dụng độ lệch chuẩn - STD</h4>
<p>Nếu biết trước rằng tập dữ liệu mà ta đang làm việc tuân theo phân phối Gaussian hoặc gần với Gaussian thì chúng ta có thể sử dụng STD để xác định và loại bỏ Outlier Data. Bởi vì, Gaussian có đặc điểm là:</p>
<ul>
<li>Các mẫu nằm trong phạm vi STD tính từ Mean sẽ chiếm khoảng 68% tổng số mẫu trong tập dữ liệu.</li>
<li>Các mẫu nằm trong phạm vi 2*STD tính từ Mean sẽ chiếm khoảng 95% tổng số mẫu trong tập dữ liệu.'</li>
<li>Các mẫu nằm trong phạm vi 3*STD tính từ Mean sẽ chiếm khoảng 99.7% tổng số mẫu trong tập dữ liệu.</li>
</ul>
<p>Ví dụ, nếu tập dữ liệu có Mean là 50 và STD là 5 thì tổng số mẫu có giá trị trong khoảng [45;55] sẽ chiếm 68% tổng số mẫu.</p>
<p>Biết được như vậy rồi, chúng ta sẽ tính Mean và STD, sau đó định nghĩa Outlier Data là các mẫu nằm ngoài phạm vi của STD (<em>hoặc 2</em>STD, hoặc 3<em>STD</em>) tính từ Mean. Code dưới đây sẽ hiện thực phương pháp này:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># identify outliers with standard deviation</span>
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> seed
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> randn
<span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> mean
<span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> std
<span style="color:#75715e"># seed the random number generator</span>
seed(<span style="color:#ae81ff">1</span>)
<span style="color:#75715e"># generate univariate observations</span>
data <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> randn(<span style="color:#ae81ff">10000</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">50</span>
<span style="color:#75715e"># calculate summary statistics</span>
data_mean, data_std <span style="color:#f92672">=</span> mean(data), std(data)
<span style="color:#75715e"># define outliers là 3*STD</span>
cut_off <span style="color:#f92672">=</span> data_std <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>
lower, upper <span style="color:#f92672">=</span> data_mean <span style="color:#f92672">-</span> cut_off, data_mean <span style="color:#f92672">+</span> cut_off
<span style="color:#75715e"># identify outliers</span>
outliers <span style="color:#f92672">=</span> [x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data <span style="color:#66d9ef">if</span> x <span style="color:#f92672">&lt;</span> lower <span style="color:#f92672">or</span> x <span style="color:#f92672">&gt;</span> upper]
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39; Identified outliers: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> len(outliers))
<span style="color:#75715e"># remove outliers</span>
outliers_removed <span style="color:#f92672">=</span> [x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data <span style="color:#66d9ef">if</span> x <span style="color:#f92672">&gt;=</span> lower <span style="color:#f92672">and</span> x <span style="color:#f92672">&lt;=</span> upper]
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39; Non-outlier observations: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> len(outliers_removed))
</code></pre></div><p>Chạy code trên, đầu tiên nó sẽ in ra số lượng Outliers, sau đó là số lượng mẫu sau khi đã loại bỏ Outliers.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Identified outliers: <span style="color:#ae81ff">29</span>
Non<span style="color:#f92672">-</span>outlier observations: <span style="color:#ae81ff">9971</span>
</code></pre></div><p>Bộ dữ liệu mà chúng ta đang sử dụng trong ví dụ này chỉ có 1 chiều (<em>univariate</em>), nhưng phương pháp này hoàn toàn có thể mở rộng ra được với dữ liệu nhiều chiều.</p>
<h4 id="22-phương-pháp-sử-dụng-khoảng-tứ-phân-vị---interquartile-range">2.2 Phương pháp sử dụng khoảng tứ phân vị - Interquartile Range</h4>
<h5 id="a-nhắc-lại-một-chút-về-trung-bình-trung-vị-tứ-phân-vị">a, Nhắc lại một chút về trung bình, trung vị, tứ phân vị.</h5>
<p>Giả sử ta có dãy số sau: 6, 5, 8, 7, 12, 13, 15, 14, 2, 200, 1. Câu hỏi đặt ra là tìm giá trị trung bình, trung vị, tứ phân vị của dãy số đó.</p>
<ul>
<li>Giá trị trung bình</li>
</ul>
<p>Giá trị trung bình chính là tổng của tất cả các số, chia cho số lượng số, ở đây số lượng số là 11 số, như vậy giá trị trung bình cộng sẽ là:</p>


<div style="text-align-last:center">
   <p>$Mean = \frac{6+5+8+7+12+13+15+14+2+200+1}{11} = 25.72$</p>
</div>


<ul>
<li>Giá trị trung vị</li>
</ul>
<p>Bước 1: Sắp xếp dãy số ở trên theo thứ tự tăng dần, ta được kết quả:1, 2, 5, 6, 7, 8, 12, 13, 14, 15, 200</p>
<p>Bước 2: Trung vị là giá trị đứng ở vị trí giữa trong một dãy số đã được sắp xếp có thứ tự. Trước và sau trị số trung vị sẽ có 50% quan sát. Dãy số ở trên có 11 số (1, 2, 5, 6, 7, 8, 12, 13, 14, 15, 200) =&gt; Số ở chính giữa là 8 sẽ chia đôi bộ số làm 2, bên trái nó có 5 số, bên phải nó có 5 số, =&gt; 8 chính là số trung vị của tập hợp ở trên( trung vị cũng còn được gọi là tứ phân vị thứ nhì).</p>
<p>Điểm khác nhau cơ bản của giá trị trung vị trong việc mô tả dữ liệu so với giá trị trung bình là nó không bị sai lệch bởi một tỷ lệ nhỏ các giá trị cực lớn hoặc cực nhỏ (<em>outliers</em>), và do đó nó cung cấp một đại diện tốt hơn về giá trị đặc trưng.</p>
<p>Trung vị của một danh sách hữu hạn các số là số <em>ở giữa</em>, khi các số đó được liệt kê theo thứ tự từ nhỏ nhất đến lớn nhất. Nếu tập dữ liệu có số lượng quan sát lẻ, thì tập ở giữa được chọn. Ví dụ: danh sách bảy số sau 1, 3, 3, 6, 7, 8, 9 có giá trị trung vị là số 6. Nếu tập hợp có số lượng quan sát là chẵn thì không có giá trị giữa. Khi đó, giá trị trung vị thường được xác định là giá trị trung bình của hai giá trị giữa. Ví dụ, tập dữ liệu 1, 2, 3, 4, 5, 6, 8, 9 có giá trị trung vị là 4.5 nghĩa là (4 + 5) / 2.</p>
<ul>
<li>Giá trị tứ phân vị</li>
</ul>
<p>Điểm tứ phân vị (<em>interquartile</em>) là giá trị bằng số phân chia một nhóm các kết quả quan sát bằng số thành bốn phần, mỗi phần có số liệu quan sát bằng nhau(<em>=25% số kết quả quan sát</em>). Tứ phân vị có 3 giá trị, đó là tứ phân vị thứ nhất (Q1), thứ nhì (Q2) và thứ ba (Q3). Ba giá trị này chia một tập hợp dữ liệu (<em>đã sắp xếp theo thứ tự từ từ bé đến lớn</em>) thành 4 phần có số lượng quan sát đều nhau.</p>
<p>Xem lại dãy số 11 số ở trên của chúng ta (1, 2, 5, 6, 7, 8, 12, 13, 14, 15, 200):</p>
<p>Giá trị tứ phân vị thứ nhất Q1 bằng trung vị phần dưới, phần dưới là các số (1, 2, 5, 6, 7), là số 5.</p>
<p>Giá trị tứ phân vị thứ hai Q2 chính bằng giá trị trung vị, là số 8.</p>
<p>Giá trị tứ phân vị thứ ba Q3 bằng trung vị phần trên (12, 13, 14, 15, 200), là số 14.</p>
<h5 id="b-mô-tả-phương-pháp">b, Mô tả phương pháp</h5>
<p>Trong thực tế, dữ liệu của chúng ta hiếm khi nào tuân theo phân phối Gaussian. Vì thế, phương pháp sử dụng Mean và STD không thể sử dụng được trong những trường hợp đó. Lúc này, tứ phân vị sẽ phát huy tác dụng. Phương pháp Interquartile Range, viết tắt là IQR, bao gồm các bước sau:</p>
<ul>
<li>Bước 1:</li>
</ul>
<p>Tính toán sai số giữa tứ phân vị thứ 3 và tứ phân vị thứ nhất: <em>IQR = Q3 - Q1</em></p>
<ul>
<li>Bước 2:</li>
</ul>
<p>Tính toán giá trị <em>cut_off</em> bằng cách nhân IQR với hệ số <em>k</em>. Giá trị của <em>k</em> thể hiện mức độ Outlier của dữ liệu. Giá trị thông thường của nó là 1.5: <em>cut_off = IQR * k</em>.</p>
<ul>
<li>Bước 3:</li>
</ul>
<p>Tính toán giá trị giới hạn trên và giới hạn dưới của Outlier: <em>lower, upper = Q1 - cut_off, Q3 + cut_off</em>.</p>
<ul>
<li>Bước 4:</li>
</ul>
<p>Các mẫu có giá trị nằm ngoài khoảng giới hạn bởi [lower; upper] được coi là Outlier.</p>
<p>Code thực hiện phương pháp này như sau:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># identify outliers with interquartile range</span>
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> seed
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> randn
<span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> percentile
<span style="color:#75715e"># seed the random number generator</span>
seed(<span style="color:#ae81ff">1</span>)
<span style="color:#75715e"># generate univariate observations</span>
data <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> randn(<span style="color:#ae81ff">10000</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">50</span>
<span style="color:#75715e"># calculate interquartile range</span>
Q1, Q3 <span style="color:#f92672">=</span> percentile(data, <span style="color:#ae81ff">25</span>), percentile(data, <span style="color:#ae81ff">75</span>)
iqr <span style="color:#f92672">=</span> Q3 <span style="color:#f92672">-</span> Q1
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39; Interquartile: Q1=</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">, Q3=</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">, IQR=</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> (Q1, Q3, iqr))
<span style="color:#75715e"># calculate the outlier cutoff</span>
cut_off <span style="color:#f92672">=</span> iqr <span style="color:#f92672">*</span> <span style="color:#ae81ff">1.5</span>
lower, upper <span style="color:#f92672">=</span> Q1 <span style="color:#f92672">-</span> cut_off, Q3 <span style="color:#f92672">+</span> cut_off
<span style="color:#75715e"># identify outliers</span>
outliers <span style="color:#f92672">=</span> [x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data <span style="color:#66d9ef">if</span> x <span style="color:#f92672">&lt;</span> lower <span style="color:#f92672">or</span> x <span style="color:#f92672">&gt;</span> upper]
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39; Identified outliers: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> len(outliers))
<span style="color:#75715e"># remove outliers</span>
outliers_removed <span style="color:#f92672">=</span> [x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data <span style="color:#66d9ef">if</span> x <span style="color:#f92672">&gt;=</span> lower <span style="color:#f92672">and</span> x <span style="color:#f92672">&lt;=</span> upper]
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39; Non-outlier observations: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> len(outliers_removed))
</code></pre></div><p>Kết quả chạy code trên, đầu tiên sẽ in ra giá trị của tứ phân vị thứ nhất và thứ 3, sau đó là số lượng Outliers, và cuối cùng là số lượng mẫu còn lại trong tập dữ liệu sau khi đã xóa đi các Outliers:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Interquartile: Q1<span style="color:#f92672">=</span><span style="color:#ae81ff">46.685</span>, Q3<span style="color:#f92672">=</span><span style="color:#ae81ff">53.359</span>, IQR<span style="color:#f92672">=</span><span style="color:#ae81ff">6.674</span>
Identified outliers: <span style="color:#ae81ff">81</span>
Non<span style="color:#f92672">-</span>outlier observations: <span style="color:#ae81ff">9919</span>
</code></pre></div><p>Đối với tập dữ liệu nhiều chiều, cách tiếp cận của phương pháp này cũng hoàn toàn tương tự.</p>
<h4 id="23-phương-pháp-sử-dụng-local-outlier-factor-lof">2.3 Phương pháp sử dụng Local Outlier Factor (LOF)</h4>
<p>LOF là một kỹ thuật khai thác ý tưởng về việc sử dụng các mẫu lân cận để phát hiện ngoại lệ. Mỗi mẫu sẽ được gán cho một giá trị <em>Score</em> thể hiện mức độ cô lập hoặc khả năng nó có thể là Outlier dựa trên quy mô của vùng lân cận của nó. Những mẫu có giá trị Score lớn nhất có nhiều khả năng là Outliers.</p>
<p>Thư viện Scikit-learn cung cấp lớp <em>LocalOutlierFactor</em> giúp chúng ta đơn giản hóa việc thực hiện phương pháp này.</p>
<p>Dưới đây, chúng ta sẽ sử dụng bộ dữ liệu <a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv">Boston Housing Dataset</a> để huấn luyện mô hình LinearRegression theo 2 cách: không xóa bỏ Outliers và có xóa bỏ Outliers sử dụng phương pháp LOF. Kết quả của 2 cách đó sẽ được mang ra so sánh với nhau.</p>
<h5 id="a-cách-1">a, Cách 1</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># evaluate model on the raw dataset</span>
<span style="color:#f92672">from</span> pandas <span style="color:#f92672">import</span> read_csv
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LinearRegression
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_absolute_error
<span style="color:#75715e"># load the dataset</span>
df <span style="color:#f92672">=</span> read_csv( <span style="color:#e6db74">&#39;housing.csv&#39;</span> , header<span style="color:#f92672">=</span>None)
<span style="color:#75715e"># retrieve the array</span>
data <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>values
<span style="color:#75715e"># split into input and output elements</span>
X, y <span style="color:#f92672">=</span> data[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], data[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
<span style="color:#75715e"># split into train and test sets</span>
X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.33</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
<span style="color:#75715e"># fit the model</span>
model <span style="color:#f92672">=</span> LinearRegression()
model<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#75715e"># evaluate the model</span>
yhat <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
<span style="color:#75715e"># evaluate predictions</span>
mae <span style="color:#f92672">=</span> mean_absolute_error(y_test, yhat)
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39;MAE: </span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> mae)
</code></pre></div><p>Kết quả thực hiện:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">MAE: <span style="color:#ae81ff">3.417</span>
</code></pre></div><h5 id="b-cách-2">b, Cách 2</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># evaluate model on training dataset with outliers removed</span>
<span style="color:#f92672">from</span> pandas <span style="color:#f92672">import</span> read_csv
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LinearRegression
<span style="color:#f92672">from</span> sklearn.neighbors <span style="color:#f92672">import</span> LocalOutlierFactor
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_absolute_error
<span style="color:#75715e"># load the dataset</span>
df <span style="color:#f92672">=</span> read_csv( <span style="color:#e6db74">&#39; housing.csv &#39;</span> , header<span style="color:#f92672">=</span>None)
<span style="color:#75715e"># retrieve the array</span>
data <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>values
<span style="color:#75715e"># split into input and output elements</span>
X, y <span style="color:#f92672">=</span> data[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], data[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
<span style="color:#75715e"># split into train and test sets</span>
X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.33</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
<span style="color:#75715e"># summarize the shape of the training dataset</span>
<span style="color:#66d9ef">print</span>(X_train<span style="color:#f92672">.</span>shape, y_train<span style="color:#f92672">.</span>shape)
<span style="color:#75715e"># identify outliers in the training dataset</span>
lof <span style="color:#f92672">=</span> LocalOutlierFactor()
yhat <span style="color:#f92672">=</span> lof<span style="color:#f92672">.</span>fit_predict(X_train)
<span style="color:#75715e"># select all rows that are not outliers</span>
mask <span style="color:#f92672">=</span> yhat <span style="color:#f92672">!=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
X_train, y_train <span style="color:#f92672">=</span> X_train[mask, :], y_train[mask]
<span style="color:#75715e"># summarize the shape of the updated training dataset</span>
<span style="color:#66d9ef">print</span>(X_train<span style="color:#f92672">.</span>shape, y_train<span style="color:#f92672">.</span>shape)
<span style="color:#75715e"># fit the model</span>
model <span style="color:#f92672">=</span> LinearRegression()
model<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#75715e"># evaluate the model</span>
yhat <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
<span style="color:#75715e"># evaluate predictions</span>
mae <span style="color:#f92672">=</span> mean_absolute_error(y_test, yhat)
<span style="color:#66d9ef">print</span>( <span style="color:#e6db74">&#39;MAE: </span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74"> &#39;</span> <span style="color:#f92672">%</span> mae)
</code></pre></div><p>Kết quả thực hiện:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">(<span style="color:#ae81ff">339</span>, <span style="color:#ae81ff">13</span>) (<span style="color:#ae81ff">339</span>,)
(<span style="color:#ae81ff">305</span>, <span style="color:#ae81ff">13</span>) (<span style="color:#ae81ff">305</span>,)
MAE: <span style="color:#ae81ff">3.356</span>
</code></pre></div><p>Số lượng mẫu giảm từ 339 -&gt; 305 sau khi xóa bỏ Outliers theo phương pháp LOF. Giá trị MAE giảm từ 3.417 -&gt; 3.356. Đó là một sự cải thiện hiệu suất đáng kể của model.</p>
<p>Ngoài LocalOutlierFactor, Scikit-learn còn cung cấp 1 lớp khác là IsolationForest (<em>tất nhiên là thuật toán cũng khác</em>) để loại bỏ Outliers. Cách sử dụng thì 2 cách hoàn toàn giống nhau. Bạn có thể thử thay LocalOutlierFactor bằng IsolationForest vào code trên rồi chạy lại xem kết quả như thế nào?</p>
<h3 id="3-kết-luận">3. Kết luận</h3>
<p>Kết thúc bài thứ 3 trong chuỗi bài viết về chủ đề Data Preparation cho ML model. Trong bài này, chúng ta đã tìm hiểu về Outliers và phương pháp xử lý chúng.</p>
<p>Toàn bộ code của bài này, các bạn có thể tham khảo tại <a href="https://github.com/tiensu/Data_Preparation_for_ML/tree/master/02_Data_Cleaning/Outlier">đây</a>.</p>
<p>Trong bài tiếp theo, chúng ta sẽ tiếp tục tìm hiểu về một vấn đề khác của Data Cleaning, đó là nhận diện và xử lý vấn đề dữ liệu bị thiếu - Missing Data. Mời các bạn đón đọc.</p>
<h3 id="4-tham-khảo">4. Tham khảo</h3>
<p>[1] Jason Brownlee, &ldquo;Data Preparation for Machine Learning&rdquo;, Book: <a href="https://machinelearningmastery.com/data-preparation-for-machine-learning/">https://machinelearningmastery.com/data-preparation-for-machine-learning/</a>.</p>

        </div>

        
        
      </div>
    </div>
  </div>
</section>



<footer>
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-12 text-center mb-5">
        <a href="https://tiensu.github.io/"><img src="https://tiensu.github.io/images/logo3.jpg" alt="SuNT&#39;s Blog | AI in Practical" style="height: auto"></a>
      </div>
               
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="tel:0869644890"><i
                class="ti-mobile mr-3 text-primary"></i>0869644890</a></li>
          
                     
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>Hanoi, Vietnam</li>
          
                     
          <li class="mb-3"><a class="text-dark" href="mailto:tiensunguyen2103@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>tiensunguyen2103@gmail.com</a>
          
          </li>
        </ul>
      </div>
      
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://www.facebook.com/tiensunguyen2103">Facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.linkedin.com/in/su-nguyen-tien-aws%C2%AE-5ba74ba6/">Linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/algorithm-optimization">Algorithm Optimization</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/attention">Attention</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/audio-classification">Audio Classification</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/autoencoder">Autoencoder</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/bert">BERT</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/cnn">CNN</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/ctc">CTC</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/data-driff">Data Driff</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/data-imbalance">Data Imbalance</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/data-preparation">Data Preparation</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/data-science">Data Science</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/deep-learning">Deep Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/docker">Docker</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/ebook">Ebook</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/ensemble-learning">Ensemble Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/face-recognition">Face Recognition</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/image-classification">Image Classification</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/kubernetes">Kubernetes</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/lstm">LSTM</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/machine-learning">Machine Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/mlops">MLOps</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/neural-network">Neural Network</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/nnl">Nnl</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/object-detection">Object Detection</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/ocr">OCR</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/one-shot-learning">One Shot Learning</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/project-management">Project Management</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/recommender-system">Recommender System</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/rnn">RNN</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/scalability">Scalability</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/siamese-network">Siamese Network</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/speech-recognition">Speech Recognition</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/speech-to-text">Speech To Text</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/text-classification">Text Classification</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/text-detection">Text Detection</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/text-generation">Text generation</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/text-recognition">Text Recognition</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/transformer">Transformer</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/xgboost">XGBoost</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://tiensu.github.io/about">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://tiensu.github.io/blog">Post</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://tiensu.github.io/contact">Contact</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2021 <a href="tiensu.github.io">SuNT</a>. All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "https://tiensu.github.io/index.json"
</script>

<!-- JS Plugins -->

<script src="https://tiensu.github.io/plugins/jQuery/jquery.min.js"></script>

<script src="https://tiensu.github.io/plugins/bootstrap/bootstrap.min.js"></script>

<script src="https://tiensu.github.io/plugins/slick/slick.min.js"></script>

<script src="https://tiensu.github.io/plugins/venobox/venobox.min.js"></script>

<script src="https://tiensu.github.io/plugins/search/fuse.min.js"></script>

<script src="https://tiensu.github.io/plugins/search/mark.js"></script>

<script src="https://tiensu.github.io/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="https://tiensu.github.io/js/script.min.js"></script>




<script src="https://cdnjs.cloudflare.com/ajax/libs/js-cookie/2.2.1/js.cookie.min.js"></script>
<div id="js-cookie-box" class="cookie-box cookie-box-hide">
	This site uses cookies. By continuing to use this website, you agree to their use. <span id="js-cookie-button" class="btn btn-sm btn-primary ml-2">I Accept</span>
</div>
<script>
	(function ($) {
		const cookieBox = document.getElementById('js-cookie-box');
		const cookieButton = document.getElementById('js-cookie-button');
		if (!Cookies.get('cookie-box')) {
			cookieBox.classList.remove('cookie-box-hide');
			cookieButton.onclick = function () {
				Cookies.set('cookie-box', true, {
					expires:  2 
				});
				cookieBox.classList.add('cookie-box-hide');
			};
		}
	})(jQuery);
</script>


<style>
.cookie-box {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  text-align: center;
  z-index: 9999;
  padding: 1rem 2rem;
  background: rgb(71, 71, 71);
  transition: all .75s cubic-bezier(.19, 1, .22, 1);
  color: #fdfdfd;
}

.cookie-box-hide {
  display: none;
}
</style>
</body>
</html>